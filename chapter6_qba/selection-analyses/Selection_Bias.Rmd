---
title: "Selection Bias"
author: "R-Walmsley"
date: "2022-05-30"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Set up names
```{r}
name_of_current_run <- "selection_third_attempt" # What's changed between second and third attempt is the additional sensitivity analysis
# NAME WHERE DATA IS
input_loc <- "../../../../paperRW2021/"
file_loc_local <- "../../useful_functions/"
```

# Load packages
```{r}
lapply(c("ggplot2", "survival", "table1", "mice"), library, character.only = TRUE)
fl <- list.files(file_loc_local)
for (file in fl){
  try(source(paste0(file_loc_local, file)))
}
```

# Load data 
```{r}
df_all <- readRDS(paste0("data/", name_of_current_run, "_ready_to_use.RDS"))
df_in <- readRDS(paste0(input_loc, "epiAnalysis/inputData/2021-06-17check_messages_ready_to_use.RDS"))
df_other <- readRDS("../../chapter3_ukb/outputs/processed_data_for_sel_bias.RDS")
```

# Variable set up 
```{r}
vars_orig <- c("sex", "ethnicity", "smoking", "alcohol", "fruit_and_veg_cats", "red_and_processed_meat_cats", "oily_fish", "TownsendDeprIndexRecruit", "education_cats")
vars_health_orig <- c("BMI", "poor_health", "meds")
vars_sr_act <-   c("Self_reported_MET_minutes_walking",
                   "Self_reported_MET_minutes_MPA",
                   "Self_reported_MET_minutes_VPA",
  "Job_involves_walking_standing",
  "Job_involves_activity", 
  "Self_reported_usual_walking_pace")
vars_biom_tab_only <- c( "Systolic_blood_pressure",
  "HbA1c",
  "C_Reactive_Protein",
  "LDL_cholesterol",
  "HDL_cholesterol",
  "Triglycerides")

var_list_minus_age <- c(vars_orig, vars_health_orig, vars_sr_act, vars_biom_tab_only)

rot_list <- list(
  "sleep" = c("sleep", "SB", "LIPA", "MVPA"),
  "SB" = c("SB", "sleep", "LIPA", "MVPA"),
  "LIPA" = c("LIPA", "sleep", "SB",  "MVPA"),
  "MVPA" = c("MVPA", "sleep", "SB", "LIPA")
)

cm <- epicoda::comp_mean(df_in, rot_list[[1]])
```

# Deal with job status 
```{r}
emp_status <- rep(NA, times = nrow(df_other))
emp_status[grepl("In paid employment or self-employed", df_other$employed_i0)] <- "Employed"
emp_status[!grepl("In paid employment or self-employed", df_other$employed_i0) & (grepl( "Retired|Looking after home and/or family|Unemployed|Unable to work because of sickness or disability|Doing unpaid or voluntary work|Full or part-time student", df_other$employed_i0))] <- "Not_employed"
emp_status[!(emp_status %in% c("Employed", "Not_employed"))] <- NA

for (var in vars_sr_act[4:5]){
  df_other[, var][emp_status == "Not_employed"] <- "Not_in_employment"
  }
```

# Merge additional columns into df_all
```{r}
df_all <- merge(df_all, df_other[,c(
  "eid", vars_sr_act, vars_biom_tab_only)], by = "eid", all.x = TRUE) # We are left joining here because df_all has already had exclusion of people with prevalent CVD
```

Note we do have an interesting question about prevalent CVD, because there could be people who "shouldn't" be here because they either have CVD or die before the start of the accelerometry study. 

- Some studies do exclude these I think... maybe I should do that. 
- But, this is a conservative assumption so it's probably ok. 

# Calculate weights
Add indicator variable of presence in analytic dataset: 
```{r}
df_all$in_analytic_sample <- df_all$eid %in% df_in$eid
```

Do some preprocessing to: 

- ensure consistent treatment of missingness
- visualise continuous variables and add a log-transformed version  
```{r}
for (var in c("baseline_age", var_list_minus_age)){
  
  print(var)
  df_all[, var][df_all[, var] == ""] <- NA
  
  # Relevel factors for modelling to make ref the largest category----------------------------------------------------------
  if (!(var %in% c("baseline_age", "BMI", "TownsendDeprIndexRecruit", vars_biom_tab_only, vars_sr_act[c(1, 2, 3)]))){
     tab <- as.data.frame(table(df_all[, var]))
     ref <- as.character(tab$Var[tab$Freq == max(tab$Freq)])
     df_all[, var] <- relevel(factor(df_all[, var]), ref = ref)
   }
  # No longer do this for ordered factors as will force factors to be ordered factors 
  
  # Examine distributions of continuous variables---------------------------------------------------------------------------
  if (var %in% c("baseline_age", "BMI", "TownsendDeprIndexRecruit", vars_biom_tab_only, vars_sr_act[c(1, 2, 3)])){
    
    # Consider distribution of continuous variables ------------------------------------------------------------------------
    print(hist(as.numeric(df_all[, var]), main = var))
    print(hist(log(as.numeric(df_all[, var]) + .1), main = paste0("log(x+.1)" , var)))
    print(min(as.numeric(df_all[, var])))
    
    # Add log-transformed variables to data frame where may be appropriate (currently over-generous) -----------------------
    if (min(as.numeric(df_all[, var]), na.rm = TRUE) == 0){
      df_all[, paste0("log_1plus_", var)] <- log(as.numeric(df_all[, var]) + 1)
    } else {
    df_all[, paste0("log_", var)] <- log(as.numeric(df_all[, var]))
  }
  }
}
df_all$baseline_age_ten_years <- as.double(df_all$baseline_age)/(365.25*10)

for (var in vars_sr_act[1:3]){
  df_all[, var] <- as.double(df_all[, var])
}

df_all$Category_METmin_walking <-  cut(df_all$Self_reported_MET_minutes_walking, c(-1, 0.5, 500.5, 1000.5, 20000 ), labels = c("No walking", "1-500", "501-1000", "1001+"))
df_all$Category_METmin_MPA <-  cut(df_all$Self_reported_MET_minutes_MPA, c(-1, 0.5, 500.5, 1000.5, 20000 ), labels = c("No moderate activity", "1-500", "501-1000", "1001+"))
df_all$Category_METmin_VPA <-  cut(df_all$Self_reported_MET_minutes_VPA, c(-1, 0.5, 500.5, 1000.5, 20000 ), labels = c("No vigorous activity", "1-500", "501-1000", "1001+"))
```

I considered using the following code to force ordering of factors. However, on reflection this may excessively constrain the nature of the relationships between categories, and so for all imputation and modelling they will be treated as unordered. 
```{r}
# var_list_ordered_factors <-
#   c("smoking",
#     "alcohol",
#     "fruit_and_veg_cats",
#     "red_and_processed_meat_cats",
#     "oily_fish",
#     "education_cats",
#     "poor_health",
#     "meds",
#     "Category_METmin_walking", 
#     "Category_METmin_MPA",
#     "Category_METmin_VPA", 
#     "Job_involves_walking_standing",
#     "Job_involves_activity",
#     "Self_reported_usual_walking_pace"
#     )
# 
# # This loop generates the model for the following code
# for (var in var_list_ordered_factors){
#   cat(paste0("df_all$", var ," <- factor(df_all$", var, ', ordered = TRUE, levels = c("', paste0(levels(df_all[, var]), collapse = '", "'), '"))'))
# }
# 
# # Now amend this code to order correctly
# df_all$smoking <-
#   factor(
#     df_all$smoking,
#     ordered = TRUE,
#     levels = c("Never", "Previous", "Current")
#   )
# df_all$alcohol <-
#   factor(
#     df_all$alcohol,
#     ordered = TRUE,
#     levels = c("Never", "< 3 times per week", "3+ times per week")
#   )
# df_all$fruit_and_veg_cats <-
#   factor(
#     df_all$fruit_and_veg_cats,
#     ordered = TRUE,
#     levels = c(
#       "Less than 3 servings/day",
#       "3-4.9 servings/day",
#       "5-7.9 servings/day",
#       "8+ servings/day"
#     )
#   )
# df_all$red_and_processed_meat_cats <-
#   factor(
#     df_all$red_and_processed_meat_cats,
#     ordered = TRUE,
#     levels = c(
#       "Less than 1 time/week",
#       "1-2.9 times/week",
#       "3-4.9 times/week",
#       "5+ times/week"
#     )
#   )
# df_all$oily_fish <-
#   factor(
#     df_all$oily_fish,
#     ordered = TRUE,
#     levels = c(
#       "< 1 time/week",
#       "1 time/week",
#       "2-4 times/ week",
#       "More than 4 times/week"
#     )
#   )
# df_all$education_cats <-
#   factor(
#     df_all$education_cats,
#     ordered = TRUE,
#     levels = c(
#       "School leaver",
#       "Further, professional or vocational education",
#       "Higher education"
#     )
#   )
# df_all$poor_health <-
#   factor(df_all$poor_health,
#          ordered = TRUE,
#          levels = c("FALSE", "TRUE"))
# df_all$meds <-
#   factor(df_all$meds,
#          ordered = TRUE,
#          levels = c("FALSE", "TRUE"))
# df_all$Category_METmin_walking <-
#   factor(
#     df_all$Category_METmin_walking,
#     ordered = TRUE,
#     levels = c("No walking", "1-500", "501-1000", "1001+")
#   )
# df_all$Category_METmin_MPA <-
#   factor(
#     df_all$Category_METmin_MPA,
#     ordered = TRUE,
#     levels = c("No moderate activity", "1-500", "501-1000", "1001+")
#   )
# df_all$Category_METmin_VPA <-
#   factor(
#     df_all$Category_METmin_VPA,
#     ordered = TRUE,
#     levels = c("No vigorous activity", "1-500", "501-1000", "1001+")
#   )
# df_all$Job_involves_walking_standing <-
#   factor(
#     df_all$Job_involves_walking_standing,
#     ordered = TRUE,
#     levels = c(
#       "Not_in_employment",
#       "Never/rarely",
#       "Sometimes",
#       "Usually",
#       "Always"
#     )
#   )
# df_all$Job_involves_activity <-
#   factor(
#     df_all$Job_involves_activity,
#     ordered = TRUE,
#     levels = c(
#       "Not_in_employment",
#       "Never/rarely",
#       "Sometimes",
#       "Usually",
#       "Always"
#     )
#   )
# df_all$Self_reported_usual_walking_pace <-
#   factor(
#     df_all$Self_reported_usual_walking_pace,
#     ordered = TRUE,
#     levels = c(
#       "Brisk pace",
#       "Steady average pace",
#       "Slow pace",
#       "None of the above"
#     )
#   )
```

Set up for logistic regression model: 

- Note I have got rid of job involves walking/standing variables as they are not that helpful and are causing a mess for imputation because of logical dependencies
```{r}
# List variables with log transformation where appropriate
var_list_imp <-
  c(
    "in_analytic_sample",
    "baseline_age_ten_years",
    "sex",
    "ethnicity",
    "smoking",
    "alcohol",
    "fruit_and_veg_cats",
    "red_and_processed_meat_cats",
    "oily_fish",
    "TownsendDeprIndexRecruit",
    "education_cats",
    "BMI",
    "poor_health",
    "meds",
    "Category_METmin_walking", 
    "Category_METmin_MPA",
    "Category_METmin_VPA", 
  #  "Job_involves_walking_standing",
  #  "Job_involves_activity",
    "Self_reported_usual_walking_pace",
    "Systolic_blood_pressure",
    "log_HbA1c",
    "log_C_Reactive_Protein",
    "LDL_cholesterol",
    "HDL_cholesterol",
    "log_Triglycerides"
  )

# Print sum of variables to use
var_sum <- paste0(var_list_imp[2:length(var_list_imp)], collapse = "+") # get the variables for use in models
```

Imputation: 
```{r}
print(Sys.time())
imp <-
  parlmice(
    df_all[, var_list_imp],
    m = 5,
    n.core = 5,
    n.imp.core = 1,
    print = F
  ) # parlmice is a parallelised version of mice
saveRDS(imp, "imputed_dataset.RDS")

imp <- readRDS("imputed_dataset.RDS")
print(Sys.time())
```

Look at properties of imputation: 
```{r}
plot(imp)
imp$meth
```

Model in whole dataset: 
```{r}
# Do model for each imputed dataset
log_inc <-
  with(
    imp,
    glm(
      as.formula(paste0("in_analytic_sample ~ ", var_sum)),
      family = binomial
    )
  )

# Pool to get coefficients
pool_model <- pool(log_inc)

summary(pool_model)

# Grab coefficients
mod_coef <-
  summary(pool_model, conf.int = TRUE, exponentiate = TRUE)[, c("term", "estimate", "2.5 %", "97.5 %")]
tab_wt_model_f <-
  cbind(mod_coef[, 1, drop = FALSE], format(round(mod_coef[, 2:4], digits = 2), nsmall = 2))
tab_wt_model_f$`OR (CI)` <-
  paste0(tab_wt_model_f[, 2],
         " (",
         tab_wt_model_f[, 3],
         ", ",
         tab_wt_model_f[, 4],
         ")")
t <-
  knitr::kable(
    tab_wt_model_f[, c("term", "OR (CI)")],
    format = "latex",
    booktabs = TRUE,
    longtable = TRUE
  )
write(t, "plots/table-weight-model.tex")
```

Do logistic regression model in each imputed dataset:
```{r}
lp_glm <- data.frame(matrix(nrow = nrow(df_all), ncol = 0)) # set up dataframe to record

# Do logistic regression model in each dataset and predict from it
for (i in 1:5){
  
  # Get out dataset from imp object
  loc_dat <- complete(imp, i)
  print(nrow(loc_dat))
  
  # Generate model 
  loc_glm <-glm(
    as.formula(paste0("in_analytic_sample ~ ", var_sum)),
    family = binomial, data = loc_dat)
  loc_p <- predict(loc_glm, newdata =loc_dat, type = "link") # Predict on link scale 
  lp_glm[, paste0("lp_", i)] <- loc_p # Merge in to recording data frame
  
  # Consider model assumptions
  cat("max VIF:", max(car::vif(loc_glm)$GVIF)) ## variance inflation

  ## Consider whether the logit as a linear function of the variable looks reasonable
  # num_vars <-   c( 
  #   "baseline_age_ten_years",
  #   "BMI",
  #   "Systolic_blood_pressure",
  #   "log_HbA1c",
  #   "log_C_Reactive_Protein",
  #   "LDL_cholesterol",
  #   "HDL_cholesterol",
  #   "log_Triglycerides"
  # )
  # for (var in num_vars){ 
  #  loc_dat$loc_p <- loc_p
  #  plot <- ggplot(loc_dat, aes_string(var, "loc_p"))+
  #    geom_point(alpha = 0.05) + 
  #    geom_smooth(method = "loess", se = FALSE) + 
  #    labs(title = var)
  #  print(plot)
  # }
  
  # Tidy up after ourselves
  rm(loc_dat, loc_glm, loc_p)
}


lp_av <- apply(lp_glm, 1, mean)
p_av <- exp(lp_av)/(1+exp(lp_av))

df_all$selec_prob <- p_av
```

... There could be an issue if there is any scrambling of rows, but we should be able to see this from table. 

Calculate Stabilised Trimmed Inverse Probability of Selection Weights: 
```{r}
selec_prob_all <-
  nrow(df_in) / nrow(df_all) # Everyone in df_all should be included in model due to imputation
df_all$inverse_wt_stab <- selec_prob_all / df_all$selec_prob # Stabilisation

# Add to analytic data
df_in <-
  merge(df_in, df_all[, c("eid", "inverse_wt_stab", "selec_prob", vars_sr_act,  vars_biom_tab_only)], by = "eid")

summary(df_all$inverse_wt_stab)

# Stabilisation changes the effective population size
# Before: 
sum(1/df_in$selec_prob)
# After:
sum(df_in$inverse_wt_stab)

# Trim weights: 
qt <- quantile(df_in$inverse_wt_stab, 0.99)
df_in$inverse_wt_stab_trim <- ifelse(df_in$inverse_wt_stab > qt, qt, df_in$inverse_wt_stab)
```

# Descriptive tables to understand behaviour of weights
Set up variables for table: 
```{r}
df_in$pa <- df_in$acc.overall.avg
df_in$age_entry_years <- as.double(df_in$age_entry)/365.25
df_in <- merge(df_in, df_all[, c("eid", vars_biom_tab_only, vars_sr_act,  "Category_METmin_walking", 
    "Category_METmin_MPA",
    "Category_METmin_VPA", 
    "Self_reported_usual_walking_pace")], all.x = TRUE)
df_in$inverse_wt_quarters <- cut(df_in$inverse_wt_stab_trim, quantile(df_in$inverse_wt_stab_trim), c("Q1 - Lowest weight", "Q2", "Q3", "Q4 - Highest weight"))

# Units
units(df_in$age_entry_years) <- "years"
units(df_in$HbA1c) <- "mmol/mol"
units(df_in$C_Reactive_Protein) <- "mg/L"
units(df_in$BMI) <- "kg/m^2"
units(df_in$LDL_cholesterol) <- "mmol/L"
units(df_in$HDL_cholesterol) <- "mmol/L"
units(df_in$Triglycerides) <- "mmol/L"
units(df_in$Category_METmin_walking) <- "MET minutes"
units(df_in$Category_METmin_MPA) <- "MET minutes"
units(df_in$Category_METmin_VPA) <- "MET minutes"


# Labels
label(df_in$pa) <- "Overall activity"
units(df_in$pa) <- "mg"
label(df_in$age_entry_years) <- "Age at accelerometer wear"
label(df_in$sex) <- "Sex"
label(df_in$ethnicity) <- "Ethnicity"
label(df_in$smoking) <- "Smoking status"
label(df_in$alcohol) <- "Alcohol consumption frequency"
label(df_in$fruit_and_veg_cats) <- "Daily fruit and vegetable consumption"
label(df_in$TownsendDeprIndexRecruit) <- "Townsend Deprivation Index"
label(df_in$education_cats) <- "Qualifications"
label(df_in$poor_health) <- "Poor self-rated health"
label(df_in$meds) <- "Medications for diabetes, cholesterol or blood pressure"
label(df_in$BMI) <- "BMI"

# Column labels
for (var in c(vars_sr_act, vars_biom_tab_only, "Category_METmin_walking", 
    "Category_METmin_MPA",
    "Category_METmin_VPA", 
    "Self_reported_usual_walking_pace")) {
  label(df_in[, var]) <- gsub("_", " ", var)
}

```

Prep variables for table:
```{r}
vs <-
  c(
    "pa",
    "age_entry_years",
    vars_orig,
    vars_health_orig,
    vars_biom_tab_only,
    "Category_METmin_walking",
    "Category_METmin_MPA",
    "Category_METmin_VPA",
    "Self_reported_usual_walking_pace")
vars_table_labels <- as.list(rep(NA, times = length(vs)))
for (i in 1:length(vs)) {
    var <- vs[i]
    label <- label(df_in[, var])
    unit <- units(df_in[, var])
    if (!is.null(unit)) {
      desc <- paste0(label, " (", unit, ")")
    }
    else {
      desc <- label
    }
    vars_table_labels[[i]] <- desc
}
names(vars_table_labels) <- vs
```


Prepare to write table:
```{r}
# CATEGORICAL RENDERER
my_render_cat <- function(x) {
  c("", sapply(stats.default(x), function(y)
    with(y,
         paste0(
           formatC(FREQ, big.mark = ","),
           " (",
           format(round(PCT, digits = 0), nsmall = 0),
           "%)"
         ))))
}


# CONTINUOUS RENDERER
my_render_cont <- function(x){
  with(
    stats.apply.rounding(stats.default(x)),
    c(
      "",
      `Mean (SD)` = sprintf("%s (%s)", MEAN, SD),
      `Median [Q1, Q3]` = sprintf("%s [%s, %s]",
                                    MEDIAN, Q1, Q3)
    )
  )
}
```

Write table:
```{r}
tab_wts <-
  table1(c(split(df_in, df_in$inverse_wt_quarters), list("Overall" = df_in)),
    labels = list(variables = vars_table_labels),
    render.categorical = my_render_cat, 
    render.cont = my_render_cont
  )
t <-
  t1kable(
    tab_wts,
    format = "latex",
    booktabs = TRUE,
    longtable = TRUE
  )
write(t,
     "plots/selection-wts.tex")


```



More d.p. table: 
```{r}
# CONTINUOUS RENDERER
my_render_cont <- function(x){
  with(
    stats.apply.rounding(stats.default(x), digits = 5),
    c(
      "",
      `Mean (SD)` = sprintf("%s (%s)", MEAN, SD),
      `Median [Q1, Q3]` = sprintf("%s [%s, %s]",
                                    MEDIAN, Q1, Q3)
    )
  )
}

tab_wts <-
  table1(c(split(df_in, df_in$inverse_wt_quarters), list("Overall" = df_in)),
    labels = list(variables = vars_table_labels),
    render.categorical = my_render_cat, 
    render.cont = my_render_cont
  )
t <-
  t1kable(
    tab_wts,
    format = "latex",
    booktabs = TRUE,
    longtable = TRUE
  )
write(t,
     "plots/selection-wts-extra-dp.tex")
```

# Modelling

## Run weighted Cox model
```{r}
act_vars <- as.matrix(df_in[, rot_list[[1]]])
rep_val <- min(act_vars[act_vars != 0])
act_vars_z <-
  zCompositions::lrEM(act_vars, label = 0, rep(rep_val, length.out = 4))
colnames(act_vars_z) <- rot_list[[1]]


rec_dat <- make_rec_dat_frame(8)

for (i in 1:length(rot_list)) {
  # set up-----------------------------------------------------
  comp_labels <- rot_list[[i]]
  comp_name <- names(rot_list)[i]

  # set up for later looking at transformation-----------------
  diff <- get_diff(comp_name)
  ilr_diff <- create_ref_vals(comp_name, cm)

  # do transformation-----------------------------------------
  piv_c <-
    as.data.frame(robCompositions::pivotCoord(act_vars_z[, comp_labels]))
  colnames(piv_c) <- c("piv1", "piv2", "piv3")

  # make new data with these variables------------------------
  loc <- cbind(df_in, piv_c)


  # basic cox model-------------------------------------------
  cox_mod_simple <- coxph(
    Surv(age_entry, age_exit, CVD_event) ~
      strata(sex) + ethnicity + smoking + alcohol +
      fruit_and_veg_cats + oily_fish +
      red_and_processed_meat_cats + education_cats +
      TDI_quartiles +
      piv1 + piv2 + piv3,
    data = loc
  )
  assign(paste0("cox_", comp_name), cox_mod_simple)
  HRs <- calc_HRs(model = cox_mod_simple, row = "piv1", ilr_diff = ilr_diff)
  ev_nums <- get_ev_nums(cox_mod_simple)
  rec_dat[(i - 1) * 2 + 1,] <- c(comp_name, diff, "unweighted", HRs, ev_nums)
  rm(HRs, ev_nums)
  
  
  # Weighted Cox model---------------------------------------- 
  cox_mod_weighted <- coxph(
    Surv(age_entry, age_exit, CVD_event) ~
      strata(sex) + ethnicity + smoking + alcohol +
      fruit_and_veg_cats + oily_fish +
      red_and_processed_meat_cats + education_cats +
      TDI_quartiles +
      piv1 + piv2 + piv3, weights = inverse_wt_stab_trim,
    data = loc, id = eid, robust = TRUE # see notes on coxph function, robust = TRUE (i.e. robust SEs) needed if weights are sampling weights.
    # This is the most likely place for errors in this code 
    # But it seemes that coxph with weights and robust = TRUE treats weights as sampling weights
  )
  assign(paste0("cox_weighted_", comp_name), cox_mod_weighted)
  HRs <- calc_HRs(model = cox_mod_weighted, row = "piv1", ilr_diff = ilr_diff)
  ev_nums <- get_ev_nums(cox_mod_weighted)
  rec_dat[(i - 1) * 2 + 2,] <- c(comp_name, diff, "weighted", HRs, ev_nums)
  rm(HRs, ev_nums)
}
```


Prep plot: 
```{r}
for (var in c("HR", "LowerCI", "UpperCI")) {
  rec_dat[, var] <- as.numeric(rec_dat[, var])
}
write.csv(rec_dat, "plots/sel_bias_estimates.csv") # This just saves the df so it's not a pain to get back if needed
```

## Make forest plot --------------------------------------------------------------
Admin:
```{r}
# In this case don't put event numbers on plot------------------------------------
print(rec_dat$n_event)
print(rec_dat$n_participant)
rec_dat$n_event <- as.double(rec_dat$n_event)
rec_dat$n_participant <- as.double(rec_dat$n_participant)
if (((range(rec_dat$n_event)[1] -  range(rec_dat$n_event)[2]) != 0)|((range(rec_dat$n_participant)[1] -  range(rec_dat$n_participant)[2])!=0)){
  stop("Stop: not zero range")
}
rec_dat$n_event <- NA
rec_dat$n_participant <- NA

# Now do plot admin --------------------------------------------------------------
rec_dat <- do_plot_admin(rec_dat, c("weighted", "unweighted"))
my_cols <- get_cols(2)
```

Make plot: 
```{r}
### Make plot----------------------------------------------------------------------
p <- # DATA AND AESTHETICS
  ggplot(data = rec_dat,
            aes(
              x = HR,
              y = BehaviourDet ,
              colour= Model,
              group = Model,
              label = label
            )) +
  # GEOMS
  geom_pointrange(position = position_dodge(0.6), aes(xmin = LowerCI, xmax = UpperCI), size = 1, shape = 18) +
  geom_text(
    size = 4.5,
    aes(x = 1.18, y = BehaviourDet, label = label),
    position = position_dodge(0.6),
    colour = "black", 
    fontface = "bold"
  ) +
  geom_vline(xintercept = 1, size = 0.75) +

  # SCALES
  scale_x_continuous(trans = "log10", breaks = c(0.9, 0.95, 1, 1.05)) +
    scale_color_manual(values = my_cols, guide = guide_legend(reverse = TRUE), na.translate = FALSE) +

  # CONSISTENT THEME
  consistent_theme

## save plot to file----------------------------------------------------------------------------------------------
svg(
  "plots/thesis-selection.svg",
  width = 10,
  height = 5
)
print(p)
dev.off()
```









# Sensitivity 

Restricted cohort: 
```{r}
df_res <- df_all[df_all$in_restricted_cohort, ]
print(nrow(df_res))
```

Imputation: 
```{r}
print(Sys.time())
imp_rest <-
  parlmice(
    df_res[, var_list_imp],
    m = 5,
    n.core = 5,
    n.imp.core = 1,
    print = F
  ) # parlmice is a parallelised version of mice
saveRDS(imp_rest, "imputed_dataset_restricted_cohort.RDS")

imp_rest <- readRDS("imputed_dataset_restricted_cohort.RDS")
print(Sys.time())
```

Look at properties of imputation: 
```{r}
plot(imp_rest)
imp_rest$meth
```

Model :
```{r}
# Do model for each imputed dataset
log_inc_rest <-
  with(
    imp_rest,
    glm(
      as.formula(paste0("in_analytic_sample ~ ", var_sum)),
      family = binomial
    )
  )

# Pool to get coefficients
pool_model_rest <- pool(log_inc_rest)

# Grab coefficients
mod_coef_rest <-
  summary(pool_model_rest, conf.int = TRUE, exponentiate = TRUE)[, c("term", "estimate", "2.5 %", "97.5 %")]
tab_wt_model_f_rest <-
  cbind(mod_coef_rest[, 1, drop = FALSE], format(round(mod_coef_rest[, 2:4], digits = 4), nsmall = 4))
tab_wt_model_f_rest$`OR (CI)` <-
  paste0(tab_wt_model_f_rest[, 2],
         " (",
         tab_wt_model_f_rest[, 3],
         ", ",
         tab_wt_model_f_rest[, 4],
         ")")
t_rest <-
  knitr::kable(
    tab_wt_model_f_rest[, c("term", "OR (CI)")],
    format = "latex",
    booktabs = TRUE,
    longtable = TRUE
  )
write(t_rest, "plots/table-weight-model-restricted.tex")
```

Do logistic regression model in each imputed dataset:
```{r}
lp_glm_rest <- data.frame(matrix(nrow = nrow(df_res), ncol = 0)) # set up dataframe to record

# Do logistic regression model in each dataset and predict from it
for (i in 1:5){
  
  # Get out dataset from imp object
  loc_dat <- complete(imp_rest, i)
  print(nrow(loc_dat))
  
  # Generate model 
  loc_glm <-glm(
    as.formula(paste0("in_analytic_sample ~ ", var_sum)),
    family = binomial, data = loc_dat)
  loc_p <- predict(loc_glm, newdata =loc_dat, type = "link") # Predict on link scale 
  lp_glm_rest[, paste0("lp_", i)] <- loc_p # Merge in to recording data frame

  # Tidy up after ourselves
  rm(loc_dat, loc_glm, loc_p)
}


lp_av_rest <- apply(lp_glm_rest, 1, mean)
p_av_rest <- exp(lp_av_rest)/(1+exp(lp_av_rest))

df_res$selec_prob <- p_av_rest
```


Calculate Stabilised Trimmed Inverse Probability of Selection Weights: 
```{r}
selec_prob_all_rest <-
  nrow(df_in) / nrow(df_res) # Everyone in df_res should be included in model due to imputation
df_res$inverse_wt_stab_rest <- selec_prob_all_rest / df_res$selec_prob # Stabilisation

# Add to analytic data
df_in <-
  merge(df_in, df_res[, c("eid", "inverse_wt_stab_rest", "selec_prob", vars_sr_act,  vars_biom_tab_only)], by = "eid")

if (nrow(df_in)!= 87498){
  stop("error in input dataset")
}


# Trim weights: 
qt <- quantile(df_in$inverse_wt_stab_rest, 0.99)
df_in$inverse_wt_stab_trim_rest <- ifelse(df_in$inverse_wt_stab_rest > qt, qt, df_in$inverse_wt_stab_rest)
```


Look at comparison between these weights and other weights: 
```{r}
hist(df_in$inverse_wt_stab_trim_rest - df_in$inverse_wt_stab_trim, breaks = seq(-0.1, 0.1, by = 0.01))
corr(df_in$inverse_wt_stab_trim, df_in$inverse_wt_stab_trim_rest)

```

## Run weighted Cox model
```{r}
act_vars <- as.matrix(df_in[, rot_list[[1]]])
rep_val <- min(act_vars[act_vars != 0])
act_vars_z <-
  zCompositions::lrEM(act_vars, label = 0, rep(rep_val, length.out = 4))
colnames(act_vars_z) <- rot_list[[1]]


rec_dat_rest <- make_rec_dat_frame(8)

for (i in 1:length(rot_list)) {
  # set up-----------------------------------------------------
  comp_labels <- rot_list[[i]]
  comp_name <- names(rot_list)[i]

  # set up for later looking at transformation-----------------
  diff <- get_diff(comp_name)
  ilr_diff <- create_ref_vals(comp_name, cm)

  # do transformation-----------------------------------------
  piv_c <-
    as.data.frame(robCompositions::pivotCoord(act_vars_z[, comp_labels]))
  colnames(piv_c) <- c("piv1", "piv2", "piv3")

  # make new data with these variables------------------------
  loc <- cbind(df_in, piv_c)


  # basic cox model-------------------------------------------
  cox_mod_simple <- coxph(
    Surv(age_entry, age_exit, CVD_event) ~
      strata(sex) + ethnicity + smoking + alcohol +
      fruit_and_veg_cats + oily_fish +
      red_and_processed_meat_cats + education_cats +
      TDI_quartiles +
      piv1 + piv2 + piv3,
    data = loc
  )
  assign(paste0("cox_", comp_name), cox_mod_simple)
  HRs <- calc_HRs(model = cox_mod_simple, row = "piv1", ilr_diff = ilr_diff)
  ev_nums <- get_ev_nums(cox_mod_simple)
  rec_dat_rest[(i - 1) * 2 + 1,] <- c(comp_name, diff, "unweighted", HRs, ev_nums)
  rm(HRs, ev_nums)
  
  
  # Weighted Cox model---------------------------------------- 
  cox_mod_weighted <- coxph(
    Surv(age_entry, age_exit, CVD_event) ~
      strata(sex) + ethnicity + smoking + alcohol +
      fruit_and_veg_cats + oily_fish +
      red_and_processed_meat_cats + education_cats +
      TDI_quartiles +
      piv1 + piv2 + piv3, weights = inverse_wt_stab_trim_rest,
    data = loc, id = eid, robust = TRUE # see notes on coxph function, robust = TRUE (i.e. robust SEs) needed if weights are sampling weights.
    # This is the most likely place for errors in this code 
    # But it seemes that coxph with weights and robust = TRUE treats weights as sampling weights
  )
  assign(paste0("cox_weighted_", comp_name), cox_mod_weighted)
  HRs <- calc_HRs(model = cox_mod_weighted, row = "piv1", ilr_diff = ilr_diff)
  ev_nums <- get_ev_nums(cox_mod_weighted)
  rec_dat_rest[(i - 1) * 2 + 2,] <- c(comp_name, diff, "weighted", HRs, ev_nums)
  rm(HRs, ev_nums)
}
```


Prep plot: 
```{r}
for (var in c("HR", "LowerCI", "UpperCI")) {
  rec_dat_rest[, var] <- as.numeric(rec_dat_rest[, var])
}
write.csv(rec_dat_rest, "plots/sel_bias_estimates_restricted_cohort.csv") # This just saves the df so it's not a pain to get back if needed
```

## Make forest plot --------------------------------------------------------------
Admin:
```{r}
# In this case don't put event numbers on plot------------------------------------
print(rec_dat_rest$n_event)
print(rec_dat_rest$n_participant)
rec_dat_rest$n_event <- NA
rec_dat_rest$n_participant <- NA

# Now do plot admin --------------------------------------------------------------
rec_dat_rest <- do_plot_admin(rec_dat_rest, c("weighted", "unweighted"))
my_cols <- get_cols(2)
```

Make plot: 
```{r}
### Make plot----------------------------------------------------------------------
p <- # DATA AND AESTHETICS
  ggplot(data = rec_dat_rest,
            aes(
              x = HR,
              y = BehaviourDet ,
              colour= Model,
              group = Model,
              label = label
            )) +
  # GEOMS
  geom_pointrange(position = position_dodge(0.6), aes(xmin = LowerCI, xmax = UpperCI), size = 1, shape = 18) +
  geom_text(
    size = 4.5,
    aes(x = 1.18, y = BehaviourDet, label = label),
    position = position_dodge(0.6),
    colour = "black", 
    fontface = "bold"
  ) +
  geom_vline(xintercept = 1, size = 0.75) +

  # SCALES
  scale_x_continuous(trans = "log10", breaks = c(0.9, 0.95, 1, 1.05)) +
    scale_color_manual(values = my_cols, guide = guide_legend(reverse = TRUE), na.translate = FALSE) +

  # CONSISTENT THEME
  consistent_theme

## save plot to file----------------------------------------------------------------------------------------------
svg(
  "plots/thesis-selection-restricted.svg",
  width = 10,
  height = 5
)
print(p)
dev.off()
```























## Additional checks: concern - weighting never makes a difference
This isn't always true:
```{r}
summary(cox_mod_simple)
summary(cox_mod_weighted)
```

Looking at % change in coef: 
```{r}
cs <- cox_mod_simple$coefficients
cw <- cox_mod_weighted$coefficients
print(100*(cw-cs)/cs)
print(cw-cs)

exp(cs[["ethnicityBlack"]])
exp(cw[["ethnicityBlack"]])
```


Look for starker examples:
```{r}
cox_mod_rcheck1 <- coxph(Surv(age_entry, age_exit, CVD_event) ~ alcohol + sex  + ethnicity + smoking, weights = df_in$inverse_wt_stab_trim,
    data = df_in, id = eid, robust = TRUE )
  
cox_mod_rcheck2 <- coxph(Surv(age_entry, age_exit, CVD_event) ~ alcohol + sex  + ethnicity + smoking, data = df_in)

print(summary(cox_mod_rcheck1))
print(summary(cox_mod_rcheck2))

summary(df_in$inverse_wt_stab_trim)

```

Still, it's broadly underwhelming.



## Simpler weights

Calculate simpler weights: 
```{r}
df_all$inverse_wt_simple <- 1 / df_all$selec_prob 

# Add to analytic data
df_in <-
  merge(df_in, df_all[, c("eid", "inverse_wt_simple")], by = "eid")
```

Cox model:
```{r}
rec_dat <- make_rec_dat_frame(16)

for (i in 1:4) {
  # set up-----------------------------------------------------
  comp_labels <- rot_list[[i]]
  comp_name <- names(rot_list)[i]

  # set up for later looking at transformation-----------------
  diff <- get_diff(comp_name)
  ilr_diff <- create_ref_vals(comp_name, cm)

  # do transformation-----------------------------------------
  piv_c <-
    as.data.frame(robCompositions::pivotCoord(act_vars_z[, comp_labels]))
  colnames(piv_c) <- c("piv1", "piv2", "piv3")

  # make new data with these variables------------------------
  loc <- cbind(df_in, piv_c)


  # basic cox model-------------------------------------------
  cox_mod_simple <- coxph(
    Surv(age_entry, age_exit, CVD_event) ~
      strata(sex) + ethnicity + smoking + alcohol +
      fruit_and_veg_cats + oily_fish +
      red_and_processed_meat_cats + education_cats +
      TDI_quartiles +
      piv1 + piv2 + piv3,
    data = loc
  )
  assign(paste0("cox_", comp_name), cox_mod_simple)
  HRs <- calc_HRs(model = cox_mod_simple, row = "piv1", ilr_diff = ilr_diff)
  ev_nums <- get_ev_nums(cox_mod_simple)
  rec_dat[(i - 1) * 4 + 1,] <- c(comp_name, diff, "unweighted", HRs, ev_nums)
  rm(HRs, ev_nums)
  
  
  # Weighted Cox model---------------------------------------- 
  cox_mod_weighted <- coxph(
    Surv(age_entry, age_exit, CVD_event) ~
      strata(sex) + ethnicity + smoking + alcohol +
      fruit_and_veg_cats + oily_fish +
      red_and_processed_meat_cats + education_cats +
      TDI_quartiles +
      piv1 + piv2 + piv3, weights = inverse_wt_stab_trim,
    data = loc, id = eid, robust = TRUE # see notes on coxph function, robust = TRUE (i.e. robust SEs) needed if weights are sampling weights.
    # This is the most likely place for errors in this code 
    # But it seemes that coxph with weights and robust = TRUE treats weights as sampling weights
  )
  assign(paste0("cox_weighted_", comp_name), cox_mod_weighted)
  HRs <- calc_HRs(model = cox_mod_weighted, row = "piv1", ilr_diff = ilr_diff)
  ev_nums <- get_ev_nums(cox_mod_weighted)
  rec_dat[(i - 1) * 4 + 2,] <- c(comp_name, diff, "weighted", HRs, ev_nums)
  rm(HRs, ev_nums)
  
    # Weighted Cox model, cluster term---------------------------------------- 
  cox_mod_alt_syntax <- coxph(
    Surv(age_entry, age_exit, CVD_event) ~
      strata(sex) + ethnicity + smoking + alcohol +
      fruit_and_veg_cats + oily_fish +
      red_and_processed_meat_cats + education_cats +
      TDI_quartiles +
      piv1 + piv2 + piv3 + cluster(eid), weights = inverse_wt_stab_trim,
    data = loc # This is based on the syntax in the Therneau-Grambsch book.
    # It should be identical but that's what I'm checking
    )
  assign(paste0("cox_alt_syntax_", comp_name), cox_mod_alt_syntax)
  HRs <- calc_HRs(model = cox_mod_alt_syntax, row = "piv1", ilr_diff = ilr_diff)
  ev_nums <- get_ev_nums(cox_mod_alt_syntax)
  rec_dat[(i - 1) * 4 + 3,] <- c(comp_name, diff, "weighted - alt syntax", HRs, ev_nums)
  rm(HRs, ev_nums)
  
  
    # Weighted Cox model, simple weights---------------------------------------- 
  cox_mod_simple_weights <- coxph(
    Surv(age_entry, age_exit, CVD_event) ~
      strata(sex) + ethnicity + smoking + alcohol +
      fruit_and_veg_cats + oily_fish +
      red_and_processed_meat_cats + education_cats +
      TDI_quartiles +
      piv1 + piv2 + piv3, weights = inverse_wt_simple,
    data = loc, id = eid, robust = TRUE # see notes on coxph function, robust = TRUE (i.e. robust SEs) needed if weights are sampling weights.
    # This is the most likely place for errors in this code 
    # But it seemes that coxph with weights and robust = TRUE treats weights as sampling weights
  )
  assign(paste0("cox_simple_weights_", comp_name), cox_mod_simple_weights)
  HRs <- calc_HRs(model = cox_mod_simple_weights, row = "piv1", ilr_diff = ilr_diff)
  ev_nums <- get_ev_nums(cox_mod_simple_weights)
  rec_dat[(i - 1) * 4 +4,] <- c(comp_name, diff, "simple_weights", HRs, ev_nums)
  rm(HRs, ev_nums)
}
```
Inspect results: 
```{r}
print(rec_dat)
```