---
title: "Within-person variation analyses for thesis"
author: "R-Walmsley"
date: "29/03/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Note location of input files
```{r}
file_loc <- "../../../repeatedMeasurements/R/"
input_loc <- "../../../../paperRW2021/"
input_loc_rm <- "../../../repeatedMeasurementsStudy/"
```


# Load packages
```{r echo = FALSE, message = FALSE, warning = FALSE}
library(survival)
library(ggplot2)
library(data.table)
library(table1)
library(knitr)
```

# Prepare functions for use in adjustment 
```{r message=FALSE, results='hide'}
fl <- list.files(file_loc)
for (file in fl){
  try(source(paste0(file_loc, file)))
}
# Sourcing functions from another project - to be replaced with install_github
```

# Load theme
```{r}
source("../../useful_functions/consistent_theme.R")
```

# Read in data 

Read in main data:
```{r}
# Prepped UKB data
df <- readRDS(paste0(input_loc, "epiAnalysis/inputData/2021-06-17check_messages_ready_to_use.RDS"))
```

Read in repeated measurements sample:
```{r}
df_rm <-
  data.frame(data.table::fread(paste0(input_loc_rm, "data/summary_data_all_with_5sec_epoch_and_ml.csv")))
```

# Quality at each repeat
```{r}
for (i in 0:4){
  good_data_cond <- (!(is.na(df_rm[, paste0("acc.overall.avg_s", i)]))) &
                  (df_rm[, paste0("quality.goodCalibration_s", i)] == 1) & 
                  (df_rm[, paste0("quality.goodWearTime_s", i)] == 1) & 
                  (df_rm[, paste0("clipsBeforeCalibration_s", i)] < 0.01*df_rm[, paste0("totalReads_s", i)]) & 
                  (df_rm[, paste0("clipsAfterCalibration_s", i)] < 0.01*df_rm[, paste0("totalReads_s", i)]) & 
                  (df_rm[, paste0("acc.overall.avg_s", i)] <100)
  df_rm[, paste0("in_s", i)] <- ifelse(good_data_cond, TRUE, FALSE)
}
df_rm$any_valid_repeat <- df_rm$in_s1 |
                                 df_rm$in_s2 | 
                                 df_rm$in_s3 | 
                                 df_rm$in_s4
```


# Exclusions in repeated measures data
```{r}
# Rep meas exclusions
#---------------------
n <- nrow(df_rm)
exc_rm <-
  data.frame("Reason" = "Starting Number",
             "n excluded" = NA,
             "n remaining" = n)

#---------------------
df_rm <- df_rm[df_rm$in_s0, ]
exc_rm <- rbind(exc_rm, 
  data.frame("Reason" = "Missing baseline",
             "n excluded" = n - nrow(df_rm),
             "n remaining" = nrow(df_rm)))
n <- nrow(df_rm)

#---------------------
df_rm$any_valid_repeat <- df_rm$in_s1 |
                                 df_rm$in_s2 | 
                                 df_rm$in_s3 | 
                                 df_rm$in_s4
df_rm <- df_rm[df_rm$any_valid_repeat,]
exc_rm <- rbind(exc_rm, data.frame("Reason" = "Missing/poor quality data for all repeats",
             "n excluded" = n - nrow(df_rm),
             "n remaining" = nrow(df_rm)))
n <- nrow(df_rm)


#---------------------
df_rm <- df_rm[df_rm$eid %in% df$eid,]
exc_rm <- rbind(exc_rm, 
  data.frame("Reason" = "Not in final analytic sample",
             "n excluded" = n - nrow(df_rm),
             "n remaining" = nrow(df_rm)))


#---------------------
print(exc_rm)
```


# Repeated measurements data prep

- Add ilr transformed variables
```{r}
rot_list <- list(
  "sleep" = c("sleep", "sedentary", "light", "MVPA"),
   "sedentary" = c("sedentary", "sleep", "light", "MVPA"),
   "light" = c("light", "sleep", "sedentary",  "MVPA"),
   "MVPA" = c("MVPA", "sleep", "sedentary", "light")
)
df$sedentary <- df$SB
df$light <- df$LIPA
for (var in rot_list[[1]]){
  df[, paste0(var, "_ML4_red_s0")] <- df[, var]
}

for (j in 1:length(rot_list)){
  for (i in 0:4){
    comp_labels <- paste0(rot_list[[j]], "_ML4_red_s", i)
    dl <- min(df$MVPA[df$MVPA>0])
    print(comp_labels)
    tl <- epicoda::transf_labels(comp_labels, transformation_type = "ilr")
  
    df_rm[, paste0(tl, i)] <- NA
    inc_ind <- !(df_rm[, paste0("excluded_s", i)]) & !(is.na(df_rm[, paste0("excluded_s", i)]))

    d <- epicoda::transform_comp(df_rm[inc_ind, ], comp_labels = comp_labels, det_limit = dl)[, tl]

    #print(head(d))
    df_rm[inc_ind, paste0(tl, "_s", i)] <-  d
    df_rm[, paste0(names(rot_list)[j], c("z1", "z2", "z3"), "_s", i)] <- df_rm[, paste0(tl, "_s", i)]
    
    if (i == 0){
      d2 <- epicoda::transform_comp(df, comp_labels = comp_labels, det_limit = dl)[, tl]
      df[, paste0(names(rot_list)[j], c("z1", "z2", "z3"), "_s", i)] <- d2[, tl]
    }

  }
}

```

# Descriptive table for repeated measurements data 

- Preprocessing
```{r}
# FORMAT AS DATE WHERE NEEDED
for (i in 0:4) {
  df_rm[, paste0("file_start_s", i)] <-
    as.Date(df_rm[, paste0("file.startTime_s", i)])
}

# MERGE IN SOME DATA
nrow(df_rm)
df_rm <- merge(df_rm, df[, c("eid", colnames(df)[!(colnames(df) %in% colnames(df_rm))])], by = "eid", sort = FALSE)
nrow(df_rm)

# SET UP VARS TO PROCESS
vars_list <- list(
  "Wear date" = "file_start_s",
  "Overall average acceleration (mg)" = "acc.overall.avg_s",
  # "Cut-point moderate-to-vigorous physical activity (hr/day)" = "CutPointMVPA.overall.avg_s",
  # "Cut-point vigorous physical activity (min/day)" = "CutPointVPA.overall.avg_s",
  "ML moderate-to-vigorous physical activity (hr/day)" = "MVPA_ML4_red_s",
  "ML light physical activity (hr/day)" = "light_ML4_red_s" ,
  "ML sedentary behaviour (hr/day)" = "sedentary_ML4_red_s",
  "ML sleep (hr/day)" = "sleep_ML4_red_s",
  "First pivot coordinate: MVPA vs rest" = "MVPAz1_s",
  "First pivot coordinate: LIPA vs rest" = "lightz1_s",
  "First pivot coordinate: SB vs rest" = "sedentaryz1_s",
  "First pivot coordinate: sleep vs rest" = "sleepz1_s"
  
)
```

- Processing
```{r}
# SET UP DATA FRAME
tab_out <-
  data.frame(
    "Variable" = rep(NA, times = length(vars_list) + 1),
    "Original (Repeat 0)" = rep(NA, times = length(vars_list) + 1),
    "Repeat 1" = rep(NA, times = length(vars_list) + 1) ,
    "Repeat 2" = rep(NA, times = length(vars_list) + 1) ,
    "Repeat 3" = rep(NA, times = length(vars_list) + 1),
    "Repeat 4" = rep(NA, times = length(vars_list) + 1),
    "Lambda (SE)" = rep(NA, times = length(vars_list) + 1)
  )

# ADD VALUES INTO DATA FRAME
tab_out[1, "Variable"] <- "n"

for (i in 0:4) {
  dmin <- df_rm[df_rm[, paste0("in_s", i)], ]
  rel_col <- grep(i, colnames(tab_out))
  
  
  # Add in number of participants
  tab_out[1, rel_col] <- nrow(dmin)
  
  
  # Iterate over variables
  for (j in 1:length(vars_list)) {
    # Pull details
    name_var <- names(vars_list)[j]
    var <- paste0(vars_list[[j]], i)
    varclean <- sub("_s0", "", var)
    
    # Do calculations that only needed once
    if (i == 0) {
      # Assign details of var to var col
      tab_out[(1 + j), "Variable"] <- name_var
      print(varclean)
      if (!(varclean %in% c("file_start", "n"))){
        print("here")
        lambda_lin <-
        calc_lambda(varclean,
                    data = df_rm,
                    covariates = c("sex", "age_entry"))
      tab_out[(1 + j), "Lambda (SE)"] <-
        paste0(round_2_dp(lambda_lin[[1]]),
               " (",
               round_2_dp(sqrt(lambda_lin[[2]])),
               ")")} else {tab_out[(1 + j), "Lambda (SE)"] <- "NA"}
      print(tab_out)
    }
    
    # Rescale data as needed
    if (grepl("hr/day", name_var)) {
      dmin$temp <- dmin[, var] * 24
    }
    else if (grepl("min/day", name_var)) {
      dmin$temp <- dmin[, var] * 24 * 60
    }
    else {
      dmin$temp <- dmin[, var]
    }
    
    # Treat date classes separately as quantile function doesn't work
    if (inherits(dmin$temp, "Date")) {
      dmin$temp <- as.numeric(dmin$temp)
      quants <- quantile(dmin$temp, c(0.25, 0.5, 0.75))
      qround <- as.Date(quants, origin = "1970-01-01")
    }
    
    # Otherwise:
    else{
      quants <- quantile(dmin$temp, c(0.25, 0.5, 0.75))
      if (grepl("VPA|z1", var)) {
        qround <- round_2_dp(quants)
      }
      else{
        qround <- round_1_dp(quants)
      }
    }
    
    
    val <- paste0(qround[2], " (", qround[1], ", ", qround[3], ")")
    tab_out[(1 + j), rel_col] <- val
    
  }
}
colnames(tab_out)
tab_out$Lambda..SE. <- NULL
tab_out_ready <- kable(tab_out,
    format = "latex",
    booktabs = TRUE,
    longtable = TRUE
  )
write(tab_out_ready,
          "plots/thesis_table_acc_by_reps.tex")

```

# Supplementary Table: Flow Diagram for repeated measurements sample
```{r}
exc_rm
```

# Descriptive table: overall and repeated measurements samples

```{r}
df$indic_rm <- as.character(df$eid %in% df_rm$eid)
df$indic_rm <- plyr::revalue(df$indic_rm, replace = c("TRUE" = "Repeated measures sample", "FALSE" = NA))

df$pa <- df$acc.overall.avg
df$age_entry_years <- as.double(df$age_entry)/365.25

# Labels
label(df$pa) <- "Overall activity"
units(df$pa) <- "mg"
label(df$age_entry_years) <- "Age at accelerometer wear"
label(df$sex) <- "Sex"
label(df$ethnicity) <- "Ethnicity"
label(df$smoking) <- "Smoking status"
label(df$alcohol) <- "Alcohol consumption frequency"
label(df$fruit_and_veg_cats) <- "Daily fruit and vegetable consumption"
label(df$TownsendDeprIndexRecruit) <- "Townsend Deprivation Index"
label(df$education_cats) <- "Qualifications"
label(df$poor_health) <- "Poor self-rated health"
label(df$meds) <- "Medications for diabetes, cholesterol or blood pressure"
label(df$BMI) <- "BMI"

# Units 
units(df$age_entry_years) <- "years"
units(df$BMI) <- "kg/m^2"

vs <- c("age_entry_years", "sex", "ethnicity", "smoking", "alcohol", "fruit_and_veg_cats", "TownsendDeprIndexRecruit", "education_cats", "BMI", "poor_health", "meds")
vars_table_labels <- as.list(rep(NA, times = length(vs)))
for (i in 1:length(vs)) {
    var <- vs[i]
    label <- label(df[, var])
    unit <- units(df[, var])
    if (!is.null(unit)) {
      desc <- paste0(label, " (", unit, ")")
    }
    else {
      desc <- label
    }
    vars_table_labels[[i]] <- desc
}
names(vars_table_labels) <- vs
```

Prepare to write table:
```{r}
# CATEGORICAL RENDERER
my_render_cat <- function(x) {
  c("", sapply(stats.default(x), function(y)
    with(y,
         paste0(
           formatC(FREQ, big.mark = ","),
           " (",
           format(round(PCT, digits = 0), nsmall = 0),
           "%)"
         ))))
}

# CATEGORICAL RENDERER
my_render_cont <- function(x){
  with(
    stats.apply.rounding(stats.default(x)),
    c(
      "",
      `Mean (SD)` = sprintf("%s (%s)", MEAN, SD),
      `Median [Q1, Q3]` = sprintf("%s [%s, %s]",
                                    MEDIAN, Q1, Q3)
    )
  )
}
```

Write table:
```{r}
supp_table_in_out <-
   table1(
    x = c(
      list("Accelerometry study population" = df),
      split(df, df$indic_rm)),
    labels = list(variables = vars_table_labels),
    render.categorical = my_render_cat, 
    render.cont = my_render_cont
  )
t <-
  t1kable(
    supp_table_in_out,
    format = "latex",
    booktabs = TRUE,
    longtable = TRUE
  )
write(t, "plots/thesis-rep-meas.tex")
```

Observations:

- stratified sampling of participants with repeated measurements

# Regression models
```{r}
coefs <- data.frame(matrix(nrow = 1, ncol = 4))
colnames(coefs) <- paste0(names(rot_list), "_pivot1")

vals_old <- data.frame(matrix(nrow = 4, ncol = 4))
colnames(vals_old) <- c("Variable", "HR", "HR_Lower_CI", "HR_Upper_CI")
vals_old$Variable <- paste0(names(rot_list), "_pivot1")

for (var in names(rot_list)) {
  # Find names of variables
  form_vars <-
    colnames(df_rm)[grepl(paste0(var, "z"), colnames(df_rm))]
  form_vars <- unique(gsub("_(.*)", "", form_vars))
  
  # Unadulterated Cox model
  form_vars_old <- paste0(form_vars, "_s0")
  form_sum_old <-  paste0(form_vars_old, collapse = "+")
  cox_basic <-
    coxph(formula(
      paste0(
        "Surv(age_entry, age_exit, CVD_event) ~ ",
        form_sum_old,
        "+ strata(sex)+
  ethnicity + smoking + alcohol + fruit_and_veg_cats + oily_fish + red_and_processed_meat_cats + education_cats + TDI_quartiles"
      )
    ), data = df)
  
  # Assign Cox model, outputs
  vals_old[vals_old$Variable == paste0(var, "_pivot1"),] <-
    c(paste0(var, "_pivot1"), summary(cox_basic)$conf.int[1, c(1, 3:4)])
  
  # Make all predictive models
  ## XXX NOTE: Change to precision weighting?? 
  models_list <- calc_models_multi(
    var_names = form_vars,
    data = df_rm,
    suffix_baseline = "_s0",
    suffix_rep = c("_s1", "_s2", "_s3", "_s4"),
    exclusion_indic = "excluded",
    covariates = c("age_entry", "sex")
  )
  
  # Make predictions
  pred_data <-
    pred_rep(models_list, newdata = df, suffix_pred = "_pred")
  
  
  # Variables for new calculation
  form_vars_new <- paste0(form_vars, "_pred")
  form_sum <- paste0(form_vars_new, collapse = "+")
  
  # Cox model
  cox_mod <-
    coxph(formula(
      paste0(
        "Surv(age_entry, age_exit, CVD_event) ~ ",
        form_sum,
        "+ strata(sex)+
  ethnicity + smoking + alcohol + fruit_and_veg_cats + oily_fish + red_and_processed_meat_cats + education_cats + TDI_quartiles"
      )
    ), data = pred_data)
  
  # Assign Cox model, outputs
  assign(paste0("cox_mod", var), cox_mod)
  coefs[, paste0(var, "_pivot1")] <-
    summary(cox_mod)$coefficients[1, 1]
  
}
```

Look at doing same model calculation using 'true multivariate' approach: 
```{r}
# Check this results in same as multivariate model
mvm <- calc_models_multi_single(
    var_names = form_vars,
    data = df_rm,
    suffix_baseline = "_s0",
    suffix_rep = c("_s1", "_s2", "_s3", "_s4"),
    exclusion_indic = "excluded",
    covariates = c("age_entry", "sex")
  )


## manually calculate variance covariance matrix to check equal
covariates <- models_list[["MVPAz1"]][[2]]
vcov_mvm <- vcov(mvm)
for (i in 1:3){
  var_name <- paste0("MVPAz", i)
  model <- models_list[[var_name]][[1]]
  X <- model.matrix(~., df_rm[, covariates]) 
  XtX <- t(X) %*% X
  vcov_mod <- solve(XtX) * sum(model$residuals ^ 2) / (model$df.residual)
  print(vcov_mod)
  print(vcov_mvm[((i-1)*6 + 1):(i*6),((i-1)*6 + 1):(i*6) ])
}
```

Consider properties of errors: 
```{r}
# Are residuals from the three models close to uncorrelated? - We don't actually need this and shouldn't expect it 
res1 <- models_list[[1]][[1]]$residuals
res2 <- models_list[[2]][[1]]$residuals
res3 <- models_list[[3]][[1]]$residuals
res <- cbind(res1, res2, res3)

print(cor(res))

err_cors <- correlate_errors(
    var_names = form_vars,
    data = df_rm,
    suffix_baseline = "_s0",
    suffix_rep = c("_s1", "_s2", "_s3", "_s4"),
    exclusion_indic = "excluded")
print(err_cors)
```

To bootstrap whole procedure:
```{r}
n_bootstrap <- 1000
ests <- data.frame(matrix(nrow = n_bootstrap, ncol = length(names(rot_list))))
colnames(ests) <- paste0(names(rot_list), "_pivot1")
ids_rm <- df_rm$eid
df_non_rm <- df[!(df$eid %in% ids_rm), ]
df_limit <- df[df$eid %in% ids_rm, ]
df_left <- df_limit[order(match(df_limit$eid, df_non_rm$eid)), ]

rm(df_limit)

for (i in 1:n_bootstrap){
  # Sample those in overlap
  df_rm_rownums_loc <- sample(nrow(df_rm), nrow(df_rm), replace = TRUE)
  df_rm_loc <- df_rm[df_rm_rownums_loc, ]
  df_left_loc <- df_left[df_rm_rownums_loc, ] 
  
  # Check this sampling is behaving correctly 
  if (any(df_left_loc$eid != df_rm_loc$eid)){
    stop("Error in subsetting code")
  }
  
  # Sample those not in overlap
  df_non_rm_loc <- df_non_rm[sample(nrow(df_non_rm), nrow(df_non_rm), replace = TRUE), ]
  
  # Check this sampling is working correctly
  if (length(intersect(df_non_rm_loc$eid, df_left_loc$eid)) != 0){
    stop("Error in sampling code - intersect of datasets non null")
  }
  
  # Concatenate datasets
  df_loc <- rbind(df_non_rm_loc, df_left_loc)
  
  if (nrow(df_loc) != nrow(df)){
    stop("Failure to get large enough bootstrap")
  }

  ## OLD METHOD: Bootstrap both separately
  # df_rm_loc <- df_rm[sample(nrow(df_rm), nrow(df_rm), replace=TRUE), ] # i.e. same bootstrap sample for all vars
  # df_loc <- df[sample(nrow(df), nrow(df), replace=TRUE), ]
  
  for (var in names(rot_list)){
    # Find names of variables
    form_vars <- colnames(df_rm_loc)[grepl(paste0(var, "z"), colnames(df_rm_loc))]
    form_vars <- unique(gsub("_(.*)", "", form_vars))
  
  # Make all predictive models
  models_list <- calc_models_multi(
    var_names = form_vars,
    data = df_rm_loc,
    suffix_baseline = "_s0",
    suffix_rep = c("_s1", "_s2", "_s3", "_s4"),
    exclusion_indic = "excluded",
    covariates = c("age_entry", "sex")
  )
  
  # Make predictions
  pred_data_loc <- pred_rep(models_list, newdata = df_loc, suffix_pred = "_pred")
 
  
  # Variables for new calculation
  form_vars_new <- paste0(form_vars, "_pred")
  form_sum <- paste0(form_vars_new, collapse = "+")
  
  # Cox model
  cox_mod <- coxph(formula(paste0("Surv(age_entry, age_exit, CVD_event) ~ ", form_sum, "+ strata(sex)+
  ethnicity + smoking + alcohol + fruit_and_veg_cats + oily_fish + red_and_processed_meat_cats + education_cats + TDI_quartiles")), data = pred_data_loc)
  
  # Store variables
  ests[i, paste0(var, "_pivot1")] <- summary(cox_mod)$coefficients[1, 1]
  
  }
}
if (!isTRUE(all.equal(colnames(ests), colnames(coefs)))){
  stop("Something went wrong in column names")
}

diffs <- ests-coefs[rep(1, nrow(ests)), colnames(ests)]

vals <- data.frame(matrix(nrow = 4, ncol = 7))
colnames(vals) <- c("Variable", "Estimate", "Lower_CI", "Upper_CI", "HR", "HR_Lower_CI", "HR_Upper_CI")
for (i in 1:length(rot_list)){
  var_name <- colnames(ests)[i]
  lq <- quantile(diffs[, var_name], 0.025)
  uq <- quantile(diffs[, var_name], 0.975)
  c <- coefs[, var_name]
  uci <- c - lq # These all need checking against notes XXX
  lci <- c - uq
  vals[i, ] <- c(var_name, c, lci, uci, exp(c), exp(lci), exp(uci))
  print(hist(diffs[, var_name])) # Check reasonableness of bootstrap distributions
}

#write.csv(vals, "plots/thesis-cox-coefs-with-meas-err-adjustment.csv")
```
Check the 2 step bootstrap (see Keogh/White)


Plots:
```{r}
cm <- epicoda::comp_mean(df, rot_list[[1]])
rec_dat <- data.frame(matrix(nrow = 8, ncol = 6))
colnames(rec_dat) <-
  c("Behaviour",
    "Difference",
    "Model",
    "HR",
    "LowerCI",
    "UpperCI")

for (i in 1:length(rot_list)) {
  comp_name <- names(rot_list)[i]
  var_name_pivot <- paste0(comp_name, "_pivot1")

  # set up for later looking at transformation
  if (comp_name == "MVPA") {
    diff <- 1 / (24 * 3)
  } else {
    diff <- 1 / 24
  }
  
  pivvar <- cm[, comp_name]
  pivvarnew <- pivvar + diff

  othvarname <- colnames(cm)[colnames(cm) != comp_name]
  othvar <- cm[, othvarname]
  othvarnew <- othvar
  for (var in othvarname) {
    othvarnew[, var] <-
      othvar[, var] - diff * othvar[, var] / sum(othvar)
  }#


  ilr_old <-
    sqrt(3 / 4) * log(pivvar / (othvar[, 1] * othvar[, 2] * othvar[, 3]) ^
                        (1 / 3))
  ilr_new <-
    sqrt(3 / 4) * log(pivvarnew / (othvarnew[, 1] * othvarnew[, 2] * othvarnew[, 3]) ^
                        (1 / 3))
  ilr_diff <- ilr_new - ilr_old
  
  # Calculate HRs associated with difference
  HRs <- as.double(vals[vals$Variable == var_name_pivot, 5:7]) ^ ilr_diff
  rec_dat[(i - 1) * 2 + 1,] <- c(comp_name, diff, "measurement_adjusted", HRs)
  
  # Calculate HRs associated with difference unadjusted 
  HRs <- as.double(vals_old[vals_old$Variable == var_name_pivot, 2:4]) ^ ilr_diff
  rec_dat[(i - 1) * 2 + 2,] <- c(comp_name, diff, "original", HRs)
}
```
Plot difference: 
```{r}
for (var in c("HR", "LowerCI", "UpperCI")) {
  rec_dat[, var] <- as.numeric(rec_dat[, var])
}

rdc <- rec_dat # This just saves the df so it's not a pain to get back if needed


## Make forest plot --------------------------------------------------------------

### This part is admin for labels etc --------------------------------------------
rec_dat$label <-
  paste0(
    round_2_dp(rec_dat$HR),
    " (",
    round_2_dp(rec_dat$LowerCI),
    ", ",
    round_2_dp(rec_dat$UpperCI),
    ")"
  )

rec_dat$Behaviour <-
  factor(rec_dat$Behaviour, ordered = TRUE, levels = rot_list[[1]])
rec_dat$BehaviourDet <- plyr::revalue(
  rec_dat$Behaviour,
  c(
    "MVPA" = "MVPA (extra 20 min/day)",
    "light" = "LIPA (extra 1 hr/day)",
    "sedentary" = "SB (extra 1 hr/day)",
    "sleep" = "Sleep (extra 1 hr/day)"
  )
)
rec_dat$Model[rec_dat$Model == "measurement_adjusted"] <- "measurement-adjusted"
rec_dat$Model <-
  factor(rec_dat$Model,
         ordered = TRUE,
         c( "measurement-adjusted", "original"))
my_cols <- c("darkred", "black" )

### Make plot----------------------------------------------------------------------
p <- # DATA AND AESTHETICS
  ggplot(data = rec_dat,
            aes(
              x = HR,
              y = BehaviourDet ,
              colour= Model,
              group = Model,
              label = label
            )) +
  
    # GEOMS
  geom_pointrange(position = position_dodge(0.6), aes(xmin = LowerCI, xmax = UpperCI), size = 1, shape = 18) +
  geom_text(
    size = 4.5,
    aes(x = 1.18, y = BehaviourDet, label = label),
    position = position_dodge(0.6),
    colour = "black", 
    fontface = "bold"
  ) +
  geom_vline(xintercept = 1, size = 0.75) +

  # SCALES
  scale_x_continuous(trans = "log10", breaks = c(0.9, 0.95, 1, 1.05)) +
  scale_color_manual(values = my_cols, guide = guide_legend(reverse = TRUE)) +
 # scale_shape_manual(values = c(18, 20), guide = "none" ) +

  # CONSISTENT THEME
  consistent_theme

## save plot to file----------------------------------------------------------------------------------------------
svg(
  "plots/thesis-multivariable.svg",
  width = 10,
  height = 5
)
print(p)
dev.off()
```

# Additional checks 

Consider similarity of results from different ML models: 
```{r}
var_check <- list(list("pa", "acc.overall.avg_s0"), 
                  list("MVPA", "MVPA_ML4_red_s0"), 
                  list("LIPA", "light_ML4_red_s0"), 
                  list("SB", "sedentary_ML4_red_s0"), 
                  list("sleep", "sleep_ML4_red_s0"), 
                  list("sleepz1_s0", "sleepz1_s0"), 
                  list("sleepz2_s0", "sleepz2_s0"), 
                  list("sleepz3_s0", "sleepz3_s0")
                  )
for (var in var_check){
  var1 <- var[[1]]
  var2 <- var[[2]]
  print(var)
  dat_temp <- merge(df_rm[, c("eid", var2)], df[, c("eid", var1)], by = "eid")
  
  if (var1 == var2){
    var1 <- paste0(var1, ".y")
    var2 <- paste0(var2, ".x")

      }
  
  diff <- dat_temp[, var1] - dat_temp[, var2]
  av <- (dat_temp[, var1] + dat_temp[, var2])/2
  print(cor(dat_temp[, var1], dat_temp[, var2]))
  print(quantile(abs(diff)))
  print(quantile(diff))
  print(quantile(abs(diff/av), na.rm = TRUE))
  print(quantile(abs(diff)/sd(dat_temp[, var1]), na.rm = TRUE))
  rm(dat_temp)
  rm(diff)
  rm(av)
}
```
