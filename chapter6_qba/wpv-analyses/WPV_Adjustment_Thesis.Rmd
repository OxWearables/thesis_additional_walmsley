---
title: "Within-person variation analyses for thesis"
author: "R-Walmsley"
date: "29/03/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Note location of input files
```{r}
file_loc <- "../../../repeatedMeasurements/R/"
file_loc_local <- "../../useful_functions/"
input_loc <- "../../../../paperRW2021/"
input_loc_rm <- "../../../repeatedMeasurementsProcessing/data/59070/"
```


# Load packages
```{r echo = FALSE, message = FALSE, warning = FALSE}
library(survival)
library(ggplot2)
library(data.table)
library(table1)
library(knitr)
```

# Prepare functions for use in adjustment 
```{r message=FALSE, results='hide'}
fl <- list.files(file_loc)
for (file in fl){
  try(source(paste0(file_loc, file)))
}
# Sourcing functions from another project - to be replaced with install_github
```

# Load helpers
```{r results = 'hide'}
fl <- list.files(file_loc_local)
for (file in fl){
  try(source(paste0(file_loc_local, file)))
}
```

# Read in data 
Read in main data:
```{r}
# Prepped UKB data
df <- readRDS(paste0(input_loc, "epiAnalysis/inputData/2021-06-17check_messages_ready_to_use.RDS"))
```

Read in repeated measurements sample:
```{r}
df_rm <-
  data.frame(data.table::fread(paste0(input_loc_rm, "summary_data_all_with_5sec_epoch_and_ml_oct21.csv")))
```

# Quality at each repeat
```{r}
for (i in 0:4){
  good_data_cond <- (!(is.na(df_rm[, paste0("acc.overall.avg_s", i)]))) &
                  (df_rm[, paste0("quality.goodCalibration_s", i)] == 1) & 
                  (df_rm[, paste0("quality.goodWearTime_s", i)] == 1) & 
                  (df_rm[, paste0("clipsBeforeCalibration_s", i)] < 0.01*df_rm[, paste0("totalReads_s", i)]) & 
                  (df_rm[, paste0("clipsAfterCalibration_s", i)] < 0.01*df_rm[, paste0("totalReads_s", i)]) & 
                  (df_rm[, paste0("acc.overall.avg_s", i)] <100)
  df_rm[, paste0("in_s", i)] <- ifelse(good_data_cond, TRUE, FALSE)
}
df_rm$any_valid_repeat <- df_rm$in_s1 |
                                 df_rm$in_s2 | 
                                 df_rm$in_s3 | 
                                 df_rm$in_s4
```

# Exclusions in repeated measures data
```{r}
n <- nrow(df_rm)
exc_rm <-
  data.frame("Reason" = "Starting Number",
             "n excluded" = NA,
             "n remaining" = n)

#--------------------
df_rm <- df_rm[is.na(df_rm$file.startTime_s1)|(df_rm$file.startTime_s1 >= as.Date("2017-01-01")), ]
exc_rm <- rbind(exc_rm, 
  data.frame("Reason" = "s1 file appears erroneous",
             "n excluded" = n - nrow(df_rm),
             "n remaining" = nrow(df_rm)))
n <- nrow(df_rm)

#---------------------
df_rm <- df_rm[df_rm$in_s0, ]
exc_rm <- rbind(exc_rm, 
  data.frame("Reason" = "Missing baseline",
             "n excluded" = n - nrow(df_rm),
             "n remaining" = nrow(df_rm)))
n <- nrow(df_rm)

#---------------------
df_rm <- df_rm[df_rm$any_valid_repeat,]
exc_rm <- rbind(exc_rm, data.frame("Reason" = "Missing/poor quality data for all repeats",
             "n excluded" = n - nrow(df_rm),
             "n remaining" = nrow(df_rm)))
n <- nrow(df_rm)


#---------------------
df_rm <- df_rm[df_rm$eid %in% df$eid,]
exc_rm <- rbind(exc_rm, 
  data.frame("Reason" = "Not in final analytic sample",
             "n excluded" = n - nrow(df_rm),
             "n remaining" = nrow(df_rm)))


#---------------------
print(exc_rm)
```
Look at time gaps: 
```{r}
min(as.double(as.Date(df_rm$file.startTime_s1) - as.Date(df_rm$file.startTime_s0)), na.rm = T)/365.25
max(as.double(as.Date(df_rm$file.startTime_s1) - as.Date(df_rm$file.startTime_s0)), na.rm = T)/365.25
min(as.double(as.Date(df_rm$file.startTime_s4) - as.Date(df_rm$file.startTime_s0)), na.rm = T)/365.25
max(as.double(as.Date(df_rm$file.startTime_s4) - as.Date(df_rm$file.startTime_s0)), na.rm = T)/365.25
```

# Repeated measurements data prep
- Add ilr transformed variables:
```{r}
# List of elements -----------------------------------------------------------------------------------------------------------
rot_list <- list(
  "sleep" = c("sleep", "sedentary", "light", "MVPA"),
  "sedentary" = c("sedentary", "sleep", "light", "MVPA"),
  "light" = c("light", "sleep", "sedentary",  "MVPA"),
  "MVPA" = c("MVPA", "sleep", "sedentary", "light")
) 

# The class labels in the repeated measurements dataset are different to in the main dataset, so relabel the main dataset to match the repeated measurements dataset ---------------------------------------------------------------------------------------------------------
df$sedentary <- df$SB
df$light <- df$LIPA
for (var in rot_list[[1]]){
  df[, paste0(var, "_ML4_red_s0")] <- df[, var]
}


# Cycle through different first pivot coordinates adding in the set of pivot coordinates with this first pivot coordinate----------------------
for (j in 1:length(rot_list)){
  for (i in 0:4){
    # Add in transformed variables for each repeat----------------------
    comp_labels <- paste0(rot_list[[j]], "_ML4_red_s", i)
    tl <- epicoda::transf_labels(comp_labels, transformation_type = "ilr")
  
    # Det limit for zero imputation------------------------------------
    dl <- min(df$MVPA[df$MVPA>0]) # This is coming from the main study as a better overall source
    
    # Set up a mask for rows which will not appear----------------------
    df_rm[, paste0(tl, i)] <- NA
    inc_ind <- !(df_rm[, paste0("excluded_s", i)]) & !(is.na(df_rm[, paste0("excluded_s", i)]))

    # Do and store transformation---------------------------------------
    d <- epicoda::transform_comp(df_rm[inc_ind, ], comp_labels = comp_labels, det_limit = dl)[, tl]

    # Put these back in the data frame with a label for the repeat-----
    df_rm[inc_ind, paste0(tl, "_s", i)] <-  d
    df_rm[, paste0(names(rot_list)[j], c("z1", "z2", "z3"), "_s", i)] <- df_rm[, paste0(tl, "_s", i)]
    
    # Only on the first repeat, also transform the data in the main dataset-------------
    if (i == 0){
      d2 <- epicoda::transform_comp(df, comp_labels = comp_labels, det_limit = dl)[, tl]
      df[, paste0(names(rot_list)[j], c("z1", "z2", "z3"), "_s", i)] <- d2[, tl]
    }

  }
}

# Note that the labelling of columns is a little weird - MVPAz2_s0 refers to z2 for the case where MVPA was the pivot at repeat 0
```

# Descriptive table for repeated measurements data 
- Preprocessing
```{r}
# FORMAT AS DATE WHERE NEEDED
for (i in 0:4) {
  df_rm[, paste0("file_start_s", i)] <-
    as.Date(df_rm[, paste0("file.startTime_s", i)])
}

# MERGE IN SOME DATA
nrow(df_rm)
df_rm <- merge(df_rm, df[, c("eid", colnames(df)[!(colnames(df) %in% colnames(df_rm))])], by = "eid", sort = FALSE)
nrow(df_rm)

# SET UP VARS TO PROCESS
vars_list <- list(
  "Wear date" = "file_start_s",
  "Overall average acceleration (mg)" = "acc.overall.avg_s",
  "ML moderate-to-vigorous physical activity (hr/day)" = "MVPA_ML4_red_s",
  "ML light physical activity (hr/day)" = "light_ML4_red_s" ,
  "ML sedentary behaviour (hr/day)" = "sedentary_ML4_red_s",
  "ML sleep (hr/day)" = "sleep_ML4_red_s",
  "First pivot coordinate: MVPA vs rest" = "MVPAz1_s",
  "First pivot coordinate: LIPA vs rest" = "lightz1_s",
  "First pivot coordinate: SB vs rest" = "sedentaryz1_s",
  "First pivot coordinate: sleep vs rest" = "sleepz1_s"
  
)
```
Make table:
```{r}
# SET UP DATA FRAME
tab_out <-
  data.frame(
    "Variable" = rep(NA, times = length(vars_list) + 1),
    "Original (Repeat 0)" = rep(NA, times = length(vars_list) + 1),
    "Repeat 1" = rep(NA, times = length(vars_list) + 1) ,
    "Repeat 2" = rep(NA, times = length(vars_list) + 1) ,
    "Repeat 3" = rep(NA, times = length(vars_list) + 1),
    "Repeat 4" = rep(NA, times = length(vars_list) + 1),
    "Lambda (SE)" = rep(NA, times = length(vars_list) + 1)
  )

# ADD VALUES INTO DATA FRAME
tab_out[1, "Variable"] <- "n"

for (i in 0:4) {
  dmin <- df_rm[df_rm[, paste0("in_s", i)], ]
  rel_col <- grep(i, colnames(tab_out))
  
  
  # Add in number of participants
  tab_out[1, rel_col] <- nrow(dmin)
  
  
  # Iterate over variables
  for (j in 1:length(vars_list)) {
    # Pull details
    name_var <- names(vars_list)[j]
    var <- paste0(vars_list[[j]], i)
    varclean <- sub("_s0", "", var)
    
    # Do calculations that only needed once
    if (i == 0) {
      # Assign details of var to var col
      tab_out[(1 + j), "Variable"] <- name_var
      print(varclean)
      if (!(varclean %in% c("file_start", "n"))){
        print("here")
        lambda_lin <-
        calc_lambda(varclean,
                    data = df_rm,
                    suffix_baseline = "_s0", 
                    suffix_rep = c("_s1", "_s2", "_s3", "_s4"), 
                    exclusion_indic = "excluded",
                    covariates = c("sex", "age_entry"))
      tab_out[(1 + j), "Lambda (SE)"] <-
        paste0(round_2_dp(lambda_lin[[1]]),
               " (",
               round_2_dp(sqrt(lambda_lin[[2]])),
               ")")} else {tab_out[(1 + j), "Lambda (SE)"] <- "NA"}
      print(tab_out)
    }
    
    # Rescale data as needed
    if (grepl("hr/day", name_var)) {
      dmin$temp <- dmin[, var] * 24
    }
    else if (grepl("min/day", name_var)) {
      dmin$temp <- dmin[, var] * 24 * 60
    }
    else {
      dmin$temp <- dmin[, var]
    }
    
    # Treat date classes separately as quantile function doesn't work
    if (inherits(dmin$temp, "Date")) {
      dmin$temp <- as.numeric(dmin$temp)
      quants <- quantile(dmin$temp, c(0.25, 0.5, 0.75))
      qround <- as.Date(quants, origin = "1970-01-01")
    }
    
    # Otherwise:
    else{
      quants <- quantile(dmin$temp, c(0.25, 0.5, 0.75))
      if (grepl("VPA|z1", var)) {
        qround <- round_2_dp(quants)
      }
      else{
        qround <- round_1_dp(quants)
      }
    }
    
    
    val <- paste0(qround[2], " (", qround[1], ", ", qround[3], ")")
    tab_out[(1 + j), rel_col] <- val
    
  }
}
colnames(tab_out)
tab_out$Lambda..SE. <- NULL
tab_out_ready <- kable(tab_out,
    format = "latex",
    booktabs = TRUE,
    longtable = TRUE
  )
write(tab_out_ready,
          "plots/thesis_table_acc_by_reps.tex")

```

# Descriptive table: overall and repeated measurements samples
Label admin:
```{r}
df$indic_rm <- as.character(df$eid %in% df_rm$eid)
df$indic_rm <- plyr::revalue(df$indic_rm, replace = c("TRUE" = "Repeated measures sample", "FALSE" = NA))

df$pa <- df$acc.overall.avg
df$age_entry_years <- as.double(df$age_entry)/365.25

# Labels
label(df$pa) <- "Overall activity"
units(df$pa) <- "mg"
label(df$age_entry_years) <- "Age at accelerometer wear"
label(df$sex) <- "Sex"
label(df$ethnicity) <- "Ethnicity"
label(df$smoking) <- "Smoking status"
label(df$alcohol) <- "Alcohol consumption frequency"
label(df$fruit_and_veg_cats) <- "Daily fruit and vegetable consumption"
label(df$TownsendDeprIndexRecruit) <- "Townsend Deprivation Index"
label(df$education_cats) <- "Qualifications"
label(df$poor_health) <- "Poor self-rated health"
label(df$meds) <- "Medications for diabetes, cholesterol or blood pressure"
label(df$BMI) <- "BMI"

# Units 
units(df$age_entry_years) <- "years"
units(df$BMI) <- "kg/m^2"

vs <- c("age_entry_years", "sex", "ethnicity", "smoking", "alcohol", "fruit_and_veg_cats", "TownsendDeprIndexRecruit", "education_cats", "BMI", "poor_health", "meds")
vars_table_labels <- as.list(rep(NA, times = length(vs)))
for (i in 1:length(vs)) {
    var <- vs[i]
    label <- label(df[, var])
    unit <- units(df[, var])
    if (!is.null(unit)) {
      desc <- paste0(label, " (", unit, ")")
    }
    else {
      desc <- label
    }
    vars_table_labels[[i]] <- desc
}
names(vars_table_labels) <- vs
```

Prepare to write table:
```{r}
# CATEGORICAL RENDERER
my_render_cat <- function(x) {
  c("", sapply(stats.default(x), function(y)
    with(y,
         paste0(
           formatC(FREQ, big.mark = ","),
           " (",
           format(round(PCT, digits = 0), nsmall = 0),
           "%)"
         ))))
}

# CATEGORICAL RENDERER
my_render_cont <- function(x){
  with(
    stats.apply.rounding(stats.default(x)),
    c(
      "",
      `Mean (SD)` = sprintf("%s (%s)", MEAN, SD),
      `Median [Q1, Q3]` = sprintf("%s [%s, %s]",
                                    MEDIAN, Q1, Q3)
    )
  )
}
```

Write table:
```{r}
supp_table_in_out <-
   table1(
    x = c(
      list("Accelerometry study population" = df),
      split(df, df$indic_rm)),
    labels = list(variables = vars_table_labels),
    render.categorical = my_render_cat, 
    render.cont = my_render_cont
  )
t <-
  t1kable(
    supp_table_in_out,
    format = "latex",
    booktabs = TRUE,
    longtable = TRUE
  )
write(t, "plots/thesis-rep-meas.tex")
```

Observations:

- stratified sampling of participants with repeated measurements

# Regression calibration procedure
## Regression calibration in full dataset
```{r}
coefs <- data.frame(matrix(nrow = 1, ncol = 4))
colnames(coefs) <- paste0(names(rot_list), "_pivot1")

vals_old <- data.frame(matrix(nrow = 4, ncol = 4))
colnames(vals_old) <- c("Variable", "HR", "HR_Lower_CI", "HR_Upper_CI")
vals_old$Variable <- paste0(names(rot_list), "_pivot1")

for (var in names(rot_list)) {
  # Find names of variables
  form_vars <-
    colnames(df_rm)[grepl(paste0(var, "z"), colnames(df_rm))]
  form_vars <- unique(gsub("_(.*)", "", form_vars))
  
  # Unadulterated Cox model
  form_vars_old <- paste0(form_vars, "_s0")
  form_sum_old <-  paste0(form_vars_old, collapse = "+")
  cox_basic <-
    coxph(formula(
      paste0(
        "Surv(age_entry, age_exit, CVD_event) ~ ",
        form_sum_old,
        "+ strata(sex)+
  ethnicity + smoking + alcohol + fruit_and_veg_cats + oily_fish + red_and_processed_meat_cats + education_cats + TDI_quartiles"
      )
    ), data = df)
  
  # Assign Cox model, outputs
  vals_old[vals_old$Variable == paste0(var, "_pivot1"),] <-
    c(paste0(var, "_pivot1"), summary(cox_basic)$conf.int[1, c(1, 3:4)])
  
  # Make all predictive models
  models_list <- calc_models_multi(
    var_names = form_vars,
    data = df_rm,
    suffix_baseline = "_s0",
    suffix_rep = c("_s1", "_s2", "_s3", "_s4"),
    exclusion_indic = "excluded",
    covariates = c("age_entry", "sex", "ethnicity", "smoking", "alcohol", "fruit_and_veg_cats", "oily_fish", "red_and_processed_meat_cats", "education_cats", "TDI_quartiles")
  )
  
  # Make predictions
  pred_data <-
    pred_rep(models_list, newdata = df, suffix_pred = "_pred")
  
  
  # Variables for new calculation
  form_vars_new <- paste0(form_vars, "_pred")
  form_sum <- paste0(form_vars_new, collapse = "+")
  
  # Cox model
  cox_mod <-
    coxph(formula(
      paste0(
        "Surv(age_entry, age_exit, CVD_event) ~ ",
        form_sum,
        "+ strata(sex)+
  ethnicity + smoking + alcohol + fruit_and_veg_cats + oily_fish + red_and_processed_meat_cats + education_cats + TDI_quartiles"
      )
    ), data = pred_data)
  
  # Assign Cox model, outputs
  assign(paste0("cox_mod", var), cox_mod)
  coefs[, paste0(var, "_pivot1")] <-
    summary(cox_mod)$coefficients[1, 1]
  
}
```

## Bootstrap the whole procedure
Sampling for the two step bootstrap is non-obvious, to ensure correct sample sizes. I have chosen to sample those with repeated measurements and without separately, to ensure the correct sample size in the final sample. 
```{r}
n_bootstrap <-  2000

# Set up data frame to record estimates
ests <- data.frame(matrix(nrow = n_bootstrap, ncol = length(names(rot_list))))
colnames(ests) <- paste0(names(rot_list), "_pivot1")

# Set up sets of ids/data subsets for sampling
ids_rm <- df_rm$eid
df_non_rm <- df[!(df$eid %in% ids_rm), ]
df_limit <- df[df$eid %in% ids_rm, ]
df_left <- df_limit[order(match(df_limit$eid, df_non_rm$eid)), ]
rm(df_limit) # Keep tidy

for (i in 1:n_bootstrap){
  # SAMPLING-------------------------------------------------------------------------------------
  # Sample those in overlap
  df_rm_rownums_loc <- sample(nrow(df_rm), nrow(df_rm), replace = TRUE)
  df_rm_loc <- df_rm[df_rm_rownums_loc, ]
  df_left_loc <- df_left[df_rm_rownums_loc, ] 
  
  # Check this sampling is behaving correctly 
  if (any(df_left_loc$eid != df_rm_loc$eid)){
    stop("Error in subsetting code")
  }
  
  # Sample those not in overlap
  df_non_rm_loc <- df_non_rm[sample(nrow(df_non_rm), nrow(df_non_rm), replace = TRUE), ]
  
  # Check this sampling is working correctly
  if (length(intersect(df_non_rm_loc$eid, df_left_loc$eid)) != 0){
    stop("Error in sampling code - intersect of datasets non null")
  }
  
  # Concatenate datasets
  df_loc <- rbind(df_non_rm_loc, df_left_loc)
  
  if (nrow(df_loc) != nrow(df)){
    stop("Failure to get correct size bootstrap")
  }
  
#  print(head(df_loc$eid))

  # CALCULATE MODELS IN BOOTSTRAP SAMPLE--------------------------------------------------------------
  # Note we are using same bootstrap samples for all rotations. This makes sense as we are essentially looking at the 
  # same model in these cases
  
  for (var in names(rot_list)){
    # Find names of variables
    form_vars <- colnames(df_rm_loc)[grepl(paste0(var, "z"), colnames(df_rm_loc))]
    form_vars <- unique(gsub("_(.*)", "", form_vars))
  
    # Make all predictive models
    models_list <- calc_models_multi(
      var_names = form_vars,
      data = df_rm_loc,
      suffix_baseline = "_s0",
      suffix_rep = c("_s1", "_s2", "_s3", "_s4"),
      exclusion_indic = "excluded",
      covariates = c("age_entry", "sex", "ethnicity", "smoking", "alcohol", "fruit_and_veg_cats", "oily_fish", "red_and_processed_meat_cats", "education_cats", "TDI_quartiles")
    )
  
    # Make predictions
    pred_data_loc <- pred_rep(models_list, newdata = df_loc, suffix_pred = "_pred")
    
    # Variables for new calculation
    form_vars_new <- paste0(form_vars, "_pred")
    form_sum <- paste0(form_vars_new, collapse = "+")
    
    # Cox model
    cox_mod <- coxph(formula(paste0("Surv(age_entry, age_exit, CVD_event) ~ ", form_sum, "+ strata(sex)+ ethnicity + smoking + alcohol + fruit_and_veg_cats + oily_fish + red_and_processed_meat_cats + education_cats + TDI_quartiles")), data = pred_data_loc)
  
  # Store variables
  ests[i, paste0(var, "_pivot1")] <- summary(cox_mod)$coefficients[1, 1]
  
  } # This closes rotation through different variables as first pivot coordinate
  
  # CLEAN --------------------------------------------------------------------------------
  rm(df_rm_rownums_loc, df_rm_loc, df_left_loc, pred_data_loc, df_loc, df_non_rm_loc)
}

# CHECK 
if (!isTRUE(all.equal(colnames(ests), colnames(coefs)))){
  stop("Something went wrong in column names")
}

# Write out bootstrap for reuse
saveRDS(ests, "bootstrap_ests_for_reuse.RDS")
```


```{r}
# Now reload data for calculations
ests <- readRDS("bootstrap_ests_for_reuse.RDS")

# CALCULATE BOOTSTRAP (BASIC OR REVERSE PERCENTILE BOOTSTRAP; PERCENTILE BOOTSTRAP)
## http://users.stat.umn.edu/~helwig/notes/npboot-notes.html#bootstrap-confidence-intervals

# For basic/reverse percentile
diffs <- ests-coefs[rep(1, nrow(ests)), colnames(ests)] # Subtract overall estimate from estimate in bootstrap sample 

# Prep data frame with values and fill it out
vals <- data.frame(matrix(nrow = 4, ncol = 11))
colnames(vals) <- c("Variable", "Estimate", "Lower_CI", "Upper_CI", "HR", "HR_Lower_CI", "HR_Upper_CI", "Lower_CI_percentile", "Upper_CI_percentile",  "HR_Lower_CI_percentile", "HR_Upper_CI_percentile")
for (i in 1:length(rot_list)){
  var_name <- colnames(ests)[i]
  
  # basic/empirical/reverse percentile
  lq <- quantile(diffs[, var_name], 0.025)
  uq <- quantile(diffs[, var_name], 0.975)
  c <- coefs[, var_name]
  uci <- c - lq 
  lci <- c - uq
  
  # percentile
  lqp <- quantile(ests[, var_name], 0.025)
  uqp <- quantile(ests[, var_name], 0.975)
  
  # return 
  vals[i, ] <- c(var_name, c, lci, uci, exp(c), exp(lci), exp(uci), lqp, uqp, exp(lqp), exp(uqp))
  
  # hist of diffs
  print(hist(diffs[, var_name])) # Check reasonableness of bootstrap distributions
}
print(vals)
write.csv(vals, "plots/thesis-cox-coefs-with-meas-err-adjustment.csv")
```
Note: provided the distribution is not too skewed the different methods to calculate the bootstrap should give similar estimates. If they do not that is a cause for concern and need to choose more carefully. 

Fortunately in the grand scheme of things there is very little difference. 
```{r}
vals <- read.csv("plots/thesis-cox-coefs-with-meas-err-adjustment.csv")
print(vals[, c("HR_Lower_CI", "HR_Lower_CI_percentile")])
print(vals[, c("HR_Upper_CI", "HR_Upper_CI_percentile")])

```

## Plots
```{r}
cm <- epicoda::comp_mean(df, rot_list[[1]])

rec_dat <- make_rec_dat_frame(8)
for (i in 1:length(rot_list)) {
  comp_name <- names(rot_list)[i]
  var_name_pivot <- paste0(comp_name, "_pivot1")

  # set up for looking at transformation
  diff <- get_diff(comp_name)
  ilr_diff <- create_ref_vals(comp_name, cm)
  
  # Calculate HRs associated with difference
  HRs <- as.double(vals[vals$Variable == var_name_pivot, c("HR", "HR_Lower_CI", "HR_Upper_CI")]) ^ ilr_diff
  ev_nums <- get_ev_nums(get(paste0("cox_mod", comp_name)))
  rec_dat[(i - 1) * 2 + 1,] <- c(comp_name, diff, "measurement_adjusted", HRs, ev_nums)
  rm(HRs, ev_nums)
  
  # Calculate HRs associated with difference unadjusted for measurement error
  HRs <- as.double(vals_old[vals_old$Variable == var_name_pivot, c("HR", "HR_Lower_CI", "HR_Upper_CI")]) ^ ilr_diff
  ev_nums <- get_ev_nums(cox_basic)
  rec_dat[(i - 1) * 2 + 2,] <- c(comp_name, diff, "original", HRs, ev_nums)
  rm(HRs, ev_nums)
}
```
Write out estimates:
```{r}
for (var in c("HR", "LowerCI", "UpperCI")) {
  rec_dat[, var] <- as.numeric(rec_dat[, var])
}

write.csv(rec_dat, "plots/rec_dat_meas_error.csv") # This just saves so it's not a pain to get back if needed
```

Plot difference:
```{r}
rec_dat <- read.csv("plots/rec_dat_meas_error.csv")
rec_dat$X <- NULL
# Don't use participant numbers on this plot
if (((range(rec_dat$n_event)[1] -  range(rec_dat$n_event)[2]) != 0)|(range(rec_dat$n_participant)[1] -  range(rec_dat$n_participant)[2]) ){
  stop("Stop: not zero range")
}
rec_dat$n_event <- NA
rec_dat$n_participant <- NA

## Make forest plot --------------------------------------------------------------

### This part is admin for labels etc --------------------------------------------
rec_dat$Model[rec_dat$Model == "measurement_adjusted"] <- "with within-person variation correction"
rec_dat <- do_plot_admin(rec_dat, mod_levels = c( "with within-person variation correction", "original"))
my_cols <- get_cols(2)

### Make plot----------------------------------------------------------------------
p <- # DATA AND AESTHETICS
  ggplot(data = rec_dat,
            aes(
              x = HR,
              y = BehaviourDet ,
              colour= Model,
              group = Model,
              label = label
            )) +
  
    # GEOMS
  geom_pointrange(position = position_dodge(0.6), aes(xmin = LowerCI, xmax = UpperCI), size = 1, shape = 18) +
  geom_text(
    size = 4.5,
    aes(x = 1.18, y = BehaviourDet, label = label),
    position = position_dodge(0.6),
    colour = "black", 
    fontface = "bold"
  ) +
  geom_vline(xintercept = 1, size = 0.75) +

  # SCALES
  scale_x_continuous(trans = "log10", breaks = c(0.9, 0.95, 1, 1.05)) +
  scale_color_manual(values = my_cols, guide = guide_legend(reverse = TRUE), na.translate = FALSE) +

  # CONSISTENT THEME
  consistent_theme

## save plot to file----------------------------------------------------------------------------------------------
svg(
  "plots/thesis-multivariable.svg",
  width = 10,
  height = 5
)
print(p)
dev.off()
```










# Additional checks

Consider properties of errors: 
*This was to understand what properties the errors have. But actually the reg cal procedure doesn't make big assumptions about this.*
```{r}
# Are residuals from the three models close to uncorrelated? - We don't actually need this and shouldn't expect it 
res1 <- models_list[[1]][[1]]$residuals
res2 <- models_list[[2]][[1]]$residuals
res3 <- models_list[[3]][[1]]$residuals
res <- cbind(res1, res2, res3)

print(cor(res))

err_cors <- correlate_errors(
    var_names = form_vars,
    data = df_rm,
    suffix_baseline = "_s0",
    suffix_rep = c("_s1", "_s2", "_s3", "_s4"),
    exclusion_indic = "excluded")
print(err_cors)
```

Consider similarity of results from different ML models: 
*This is important as I'm using reprocessed data. It's important they're essentially comparable. It's the 'same measurement' for practical purposes.*
```{r}
var_check <- list(list("pa", "acc.overall.avg_s0"), 
                  list("MVPA", "MVPA_ML4_red_s0"), 
                  list("LIPA", "light_ML4_red_s0"), 
                  list("SB", "sedentary_ML4_red_s0"), 
                  list("sleep", "sleep_ML4_red_s0"), 
                  list("sleepz1_s0", "sleepz1_s0"), 
                  list("sleepz2_s0", "sleepz2_s0"), 
                  list("sleepz3_s0", "sleepz3_s0")
                  )
for (var in var_check){
  var1 <- var[[1]]
  var2 <- var[[2]]
  print(var)
  dat_temp <- merge(df_rm[, c("eid", var2)], df[, c("eid", var1)], by = "eid")
  
  if (var1 == var2){
    var1 <- paste0(var1, ".y")
    var2 <- paste0(var2, ".x")

      }
  
  diff <- dat_temp[, var1] - dat_temp[, var2]
  av <- (dat_temp[, var1] + dat_temp[, var2])/2
  print(cor(dat_temp[, var1], dat_temp[, var2]))
  print(quantile(abs(diff)))
  print(quantile(diff))
  print(quantile(abs(diff/av), na.rm = TRUE))
  print(quantile(abs(diff)/sd(dat_temp[, var1]), na.rm = TRUE))
  rm(dat_temp)
  rm(diff)
  rm(av)
}
```


Consider the assumptions of the linear models used in prediction:
```{r}
for (var in names(rot_list)){
  # Find names of variables
  form_vars <-
    colnames(df_rm)[grepl(paste0("^", var, "z"), colnames(df_rm))]
  form_vars <- unique(gsub("_(.*)", "", form_vars))
  
  form_vars_old <- paste0(form_vars, "_s0")
  
   for (var_name in form_vars){
    # Mean of relevant repeat is outcome
    df_rm[, paste0("mean_reps_w_data", var_name)] <- calc_mean_reps(var_name = var_name, data = df_rm, suffix_rep = c("_s1", "_s2", "_s3", "_s4"), exclusion_indic = "excluded")

    # Calc model
    lambda_lin <- lm(as.formula(paste0("mean_reps_w_data", var_name, "~", paste0(form_vars_old, collapse = "+"), "+age_entry+sex+ethnicity+smoking+alcohol+fruit_and_veg_cats+oily_fish+red_and_processed_meat_cats+education_cats+TDI_quartiles")), data = df_rm)
    pred <- predict(lambda_lin, df_rm)
    print(length(pred))
    print(cor(pred, as.double(df_rm$age_entry)))
    
  # Plot
  plot(lambda_lin)
   }

}
```

# Check regression calibration functions 

# Use slower functions for regression calibration: 
```{r}
coefs_check <- data.frame(matrix(nrow = 1, ncol = 4))
colnames(coefs_check) <- paste0(names(rot_list), "_pivot1")

vals_old <- data.frame(matrix(nrow = 4, ncol = 4))
colnames(vals_old) <- c("Variable", "HR", "HR_Lower_CI", "HR_Upper_CI")
vals_old$Variable <- paste0(names(rot_list), "_pivot1")

for (var in names(rot_list)) {
  # Find names of variables
  form_vars <-
    colnames(df_rm)[grepl(paste0(var, "z"), colnames(df_rm))]
  form_vars <- unique(gsub("_(.*)", "", form_vars))
  
  # Unadulterated Cox model
  form_vars_old <- paste0(form_vars, "_s0")
  form_sum_old <-  paste0(form_vars_old, collapse = "+")
  cox_basic <-
    coxph(formula(
      paste0(
        "Surv(age_entry, age_exit, CVD_event) ~ ",
        form_sum_old,
        "+ strata(sex)+
  ethnicity + smoking + alcohol + fruit_and_veg_cats + oily_fish + red_and_processed_meat_cats + education_cats + TDI_quartiles"
      )
    ), data = df)
  
  # Assign Cox model, outputs
  vals_old[vals_old$Variable == paste0(var, "_pivot1"),] <-
    c(paste0(var, "_pivot1"), summary(cox_basic)$conf.int[1, c(1, 3:4)])
  
  # Make all predictive models
  models_list <- calc_models_multi_slow(
    var_names = form_vars,
    data = df_rm,
    suffix_baseline = "_s0",
    suffix_rep = c("_s1", "_s2", "_s3", "_s4"),
    exclusion_indic = "excluded",
    covariates = c("age_entry", "sex", "ethnicity", "smoking", "alcohol", "fruit_and_veg_cats", "oily_fish", "red_and_processed_meat_cats", "education_cats", "TDI_quartiles")
  )

  # Make predictions
  pred_data <-
    pred_rep_slow(models_list, newdata = df, suffix_pred = "_pred")


  # Variables for new calculation
  form_vars_new <- paste0(form_vars, "_pred")
  form_sum <- paste0(form_vars_new, collapse = "+")

  # Cox model
  cox_mod <-
    coxph(formula(
      paste0(
        "Surv(age_entry, age_exit, CVD_event) ~ ",
        form_sum,
        "+ strata(sex)+
  ethnicity + smoking + alcohol + fruit_and_veg_cats + oily_fish + red_and_processed_meat_cats + education_cats + TDI_quartiles"
      )
    ), data = pred_data)

  # Assign Cox model, outputs
  assign(paste0("cox_mod_check", var), cox_mod)
  coefs_check[, paste0(var, "_pivot1")] <-
    summary(cox_mod)$coefficients[1, 1]

}
```

