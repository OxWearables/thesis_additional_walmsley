---
title: "Within-person variation analyses for thesis"
author: "R-Walmsley"
date: "29/03/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Note location of input files
```{r}
file_loc <- "../../../repeatedMeasurements/R/"
file_loc_local <- "../../useful_functions/"
input_loc <- "../../../../paperRW2021/"
input_loc_rm <- "../../../repeatedMeasurementsProcessing/data/59070/"
```

# Load packages
```{r echo = FALSE, message = FALSE, warning = FALSE}
library(survival)
library(ggplot2)
library(data.table)
library(table1)
library(knitr)
```

# Prepare functions for use in adjustment 
```{r message=FALSE, results='hide'}
fl <- list.files(file_loc)
for (file in fl){
  try(source(paste0(file_loc, file)))
}
# Sourcing functions from another project - to be replaced with install_github
```

# Load helpers
```{r results = 'hide'}
fl <- list.files(file_loc_local)
for (file in fl){
  try(source(paste0(file_loc_local, file)))
}
```

# Read in data 
Read in main data:
```{r}
# Prepped UKB data
df <- readRDS(paste0(input_loc, "epiAnalysis/inputData/2021-06-17check_messages_ready_to_use.RDS"))
```

Read in repeated measurements sample:
```{r}
df_rm <-
  data.frame(data.table::fread(paste0(input_loc_rm, "summary_data_all_with_5sec_epoch_and_ml_oct21.csv")))
```
# Quality at each repeat
```{r}
for (i in 0:4){
  good_data_cond <- (!(is.na(df_rm[, paste0("acc.overall.avg_s", i)]))) &
                  (df_rm[, paste0("quality.goodCalibration_s", i)] == 1) & 
                  (df_rm[, paste0("quality.goodWearTime_s", i)] == 1) & 
                  (df_rm[, paste0("clipsBeforeCalibration_s", i)] < 0.01*df_rm[, paste0("totalReads_s", i)]) & 
                  (df_rm[, paste0("clipsAfterCalibration_s", i)] < 0.01*df_rm[, paste0("totalReads_s", i)]) & 
                  (df_rm[, paste0("acc.overall.avg_s", i)] <100)
  df_rm[, paste0("in_s", i)] <- ifelse(good_data_cond, TRUE, FALSE)
}
df_rm$any_valid_repeat <- df_rm$in_s1 |
                                 df_rm$in_s2 | 
                                 df_rm$in_s3 | 
                                 df_rm$in_s4
```

# Exclusions in repeated measures data
```{r}
n <- nrow(df_rm)
exc_rm <-
  data.frame("Reason" = "Starting Number",
             "n excluded" = NA,
             "n remaining" = n)

#--------------------
df_rm <- df_rm[is.na(df_rm$file.startTime_s1)|(df_rm$file.startTime_s1 >= as.Date("2017-01-01")), ]
exc_rm <- rbind(exc_rm, 
  data.frame("Reason" = "s1 file appears erroneous",
             "n excluded" = n - nrow(df_rm),
             "n remaining" = nrow(df_rm)))
n <- nrow(df_rm)

#---------------------
df_rm <- df_rm[df_rm$in_s0, ]
exc_rm <- rbind(exc_rm, 
  data.frame("Reason" = "Missing baseline",
             "n excluded" = n - nrow(df_rm),
             "n remaining" = nrow(df_rm)))
n <- nrow(df_rm)

#---------------------
df_rm <- df_rm[df_rm$any_valid_repeat,]
exc_rm <- rbind(exc_rm, data.frame("Reason" = "Missing/poor quality data for all repeats",
             "n excluded" = n - nrow(df_rm),
             "n remaining" = nrow(df_rm)))
n <- nrow(df_rm)


#---------------------
df_rm <- df_rm[df_rm$eid %in% df$eid,]
exc_rm <- rbind(exc_rm, 
  data.frame("Reason" = "Not in final analytic sample",
             "n excluded" = n - nrow(df_rm),
             "n remaining" = nrow(df_rm)))


#---------------------
print(exc_rm)
```


# Repeated measurements data prep
- Add ilr transformed variables:
```{r}
# List of elements -----------------------------------------------------------------------------------------------------------
rot_list <- list(
  "sleep" = c("sleep", "sedentary", "light", "MVPA"),
  "sedentary" = c("sedentary", "sleep", "light", "MVPA"),
  "light" = c("light", "sleep", "sedentary",  "MVPA"),
  "MVPA" = c("MVPA", "sleep", "sedentary", "light")
) 

# The class labels in the repeated measurements dataset are different to in the main dataset, so relabel the main dataset to match the repeated measurements dataset ---------------------------------------------------------------------------------------------------------
df$sedentary <- df$SB
df$light <- df$LIPA
for (var in rot_list[[1]]){
  df[, paste0(var, "_ML4_red_s0")] <- df[, var]
}


# Cycle through different first pivot coordinates adding in the set of pivot coordinates with this first pivot coordinate----------------------
for (j in 1:length(rot_list)){
  for (i in 0:4){
    # Add in transformed variables for each repeat----------------------
    comp_labels <- paste0(rot_list[[j]], "_ML4_red_s", i)
    tl <- epicoda::transf_labels(comp_labels, transformation_type = "ilr")
  
    # Det limit for zero imputation------------------------------------
    dl <- min(df$MVPA[df$MVPA>0]) # This is coming from the main study as a better overall source
    
    # Set up a mask for rows which will not appear----------------------
    df_rm[, paste0(tl, i)] <- NA
    inc_ind <- !(df_rm[, paste0("excluded_s", i)]) & !(is.na(df_rm[, paste0("excluded_s", i)]))

    # Do and store transformation---------------------------------------
    d <- epicoda::transform_comp(df_rm[inc_ind, ], comp_labels = comp_labels, det_limit = dl)[, tl]

    # Put these back in the data frame with a label for the repeat-----
    df_rm[inc_ind, paste0(tl, "_s", i)] <-  d
    df_rm[, paste0(names(rot_list)[j], c("z1", "z2", "z3"), "_s", i)] <- df_rm[, paste0(tl, "_s", i)]
    
    # Only on the first repeat, also transform the data in the main dataset-------------
    if (i == 0){
      d2 <- epicoda::transform_comp(df, comp_labels = comp_labels, det_limit = dl)[, tl]
      df[, paste0(names(rot_list)[j], c("z1", "z2", "z3"), "_s", i)] <- d2[, tl]
    }

  }
}

# Note that the labelling of columns is a little weird - MVPAz2_s0 refers to z2 for the case where MVPA was the pivot at repeat 0
```

# Descriptive table for repeated measurements data 
- Preprocessing
```{r}
# FORMAT AS DATE WHERE NEEDED
for (i in 0:4) {
  df_rm[, paste0("file_start_s", i)] <-
    as.Date(df_rm[, paste0("file.startTime_s", i)])
}

# MERGE IN SOME DATA
nrow(df_rm)
df_rm <- merge(df_rm, df[, c("eid", colnames(df)[!(colnames(df) %in% colnames(df_rm))])], by = "eid", sort = FALSE)
nrow(df_rm)

# SET UP VARS TO PROCESS
vars_list <- list(
  "Wear date" = "file_start_s",
  "Overall average acceleration (mg)" = "acc.overall.avg_s",
  "ML moderate-to-vigorous physical activity (hr/day)" = "MVPA_ML4_red_s",
  "ML light physical activity (hr/day)" = "light_ML4_red_s" ,
  "ML sedentary behaviour (hr/day)" = "sedentary_ML4_red_s",
  "ML sleep (hr/day)" = "sleep_ML4_red_s",
  "First pivot coordinate: MVPA vs rest" = "MVPAz1_s",
  "First pivot coordinate: LIPA vs rest" = "lightz1_s",
  "First pivot coordinate: SB vs rest" = "sedentaryz1_s",
  "First pivot coordinate: sleep vs rest" = "sleepz1_s"
  
)
```

Make table:
```{r}
# SET UP DATA FRAME
tab_out <-
  data.frame(
    "Variable" = rep(NA, times = length(vars_list) + 1),
    "Original (Repeat 0)" = rep(NA, times = length(vars_list) + 1),
    "Repeat 1" = rep(NA, times = length(vars_list) + 1) ,
    "Repeat 2" = rep(NA, times = length(vars_list) + 1) ,
    "Repeat 3" = rep(NA, times = length(vars_list) + 1),
    "Repeat 4" = rep(NA, times = length(vars_list) + 1),
    "Lambda (SE)" = rep(NA, times = length(vars_list) + 1)
  )

# ADD VALUES INTO DATA FRAME
tab_out[1, "Variable"] <- "n"

for (i in 0:4) {
  dmin <- df_rm[df_rm[, paste0("in_s", i)],]
  rel_col <- grep(i, colnames(tab_out))
  
  
  # Add in number of participants
  tab_out[1, rel_col] <- nrow(dmin)
  
  
  # Iterate over variables
  for (j in 1:length(vars_list)) {
    # Pull details
    name_var <- names(vars_list)[j]
    var <- paste0(vars_list[[j]], i)
    varclean <- sub("_s0", "", var)
    
    # Do calculations that only needed once
    if (i == 0) {
      # Assign details of var to var col
      tab_out[(1 + j), "Variable"] <- name_var
      print(varclean)
      if (!(varclean %in% c("file_start", "n"))) {
        
        lambda_lin <-
          calc_lambda(varclean,
                      data = df_rm,
                      covariates = c("sex", "age_entry"))
        lambda_lin_pw <-
          calc_lambda(
            varclean,
            data = df_rm,
            covariates = c("sex", "age_entry"),
            precision_weighted = TRUE
          )
        tab_out[(1 + j), c("Lambda (SE)", "Lambda (SE) with precision weighting")] <-
          c(paste0(round_2_dp(lambda_lin[[1]]),
                 " (",
                 round_2_dp(sqrt(lambda_lin[[2]])),
                 ")"), paste0(round_2_dp(lambda_lin_pw[[1]]),
                 " (",
                 round_2_dp(sqrt(lambda_lin_pw[[2]])),
                 ")"))
      } else {
        tab_out[(1 + j), c("Lambda (SE)", "Lambda (SE) with precision weighting")] <-
          c("NA", "NA")
      }
    }
    
    # Rescale data as needed
    if (grepl("hr/day", name_var)) {
      dmin$temp <- dmin[, var] * 24
    }
    else if (grepl("min/day", name_var)) {
      dmin$temp <- dmin[, var] * 24 * 60
    }
    else {
      dmin$temp <- dmin[, var]
    }
    
    # Treat date classes separately as quantile function doesn't work
    if (inherits(dmin$temp, "Date")) {
      dmin$temp <- as.numeric(dmin$temp)
      quants <- quantile(dmin$temp, c(0.25, 0.5, 0.75))
      qround <- as.Date(quants, origin = "1970-01-01")
    }
    
    # Otherwise:
    else{
      quants <- quantile(dmin$temp, c(0.25, 0.5, 0.75))
      if (grepl("VPA|z1", var)) {
        qround <- round_2_dp(quants)
      }
      else{
        qround <- round_1_dp(quants)
      }
    }
    
    
    val <- paste0(qround[2], " (", qround[1], ", ", qround[3], ")")
    tab_out[(1 + j), rel_col] <- val
    
  }
}
tab_out$Lambda..SE. <- NULL
```

# Regression calibration procedure
## Regression calibration in full dataset
```{r}
coefs <- data.frame(matrix(nrow = 1, ncol = 0))

vals_old <- data.frame(matrix(nrow = 4, ncol = 4))
colnames(vals_old) <-
  c("Variable", "HR", "HR_Lower_CI", "HR_Upper_CI")
vals_old$Variable <- paste0(names(rot_list), "_pivot1")

for (var in names(rot_list)) {
  # Find names of variables
  form_vars <-
    colnames(df_rm)[grepl(paste0(var, "z"), colnames(df_rm))]
  form_vars <- unique(gsub("_(.*)", "", form_vars))
  
  # Unadulterated Cox model
  form_vars_old <- paste0(form_vars, "_s0")
  form_sum_old <-  paste0(form_vars_old, collapse = "+")
  cox_basic <-
    coxph(formula(
      paste0(
        "Surv(age_entry, age_exit, CVD_event) ~ ",
        form_sum_old,
        "+ strata(sex)+
  ethnicity + smoking + alcohol + fruit_and_veg_cats + oily_fish + red_and_processed_meat_cats + education_cats + TDI_quartiles"
      )
    ), data = df)
  
  # Assign Cox model, outputs
  vals_old[vals_old$Variable == paste0(var, "_pivot1"), ] <-
    c(paste0(var, "_pivot1"), summary(cox_basic)$conf.int[1, c(1, 3:4)])
  
  # Make all predictive models
  # WITHOUT WEIGHTING
  models_list <- calc_models_multi(
    var_names = form_vars,
    data = df_rm,
    suffix_baseline = "_s0",
    suffix_rep = c("_s1", "_s2", "_s3", "_s4"),
    exclusion_indic = "excluded",
    covariates = c(
      "age_entry",
      "sex",
      "ethnicity",
      "smoking",
      "alcohol",
      "fruit_and_veg_cats",
      "oily_fish",
      "red_and_processed_meat_cats",
      "education_cats",
      "TDI_quartiles"
    )
  )
  
  # WITH PRECISION WEIGHTING
  models_list_weighted <- calc_models_multi(
    var_names = form_vars,
    data = df_rm,
    suffix_baseline = "_s0",
    suffix_rep = c("_s1", "_s2", "_s3", "_s4"),
    exclusion_indic = "excluded",
    covariates = c(
      "age_entry",
      "sex",
      "ethnicity",
      "smoking",
      "alcohol",
      "fruit_and_veg_cats",
      "oily_fish",
      "red_and_processed_meat_cats",
      "education_cats",
      "TDI_quartiles"
    ), 
    precision_weighted = TRUE
  )
  
  
  # Make predictions
  pred_data <-
    pred_rep(models_list, newdata = df, suffix_pred = "_pred")
  
  pred_data_weighted <- 
    pred_rep(models_list_weighted, newdata = df, suffix_pred = "_pred")
  
  
  # Variables for new calculation
  form_vars_new <- paste0(form_vars, "_pred")
  form_sum <- paste0(form_vars_new, collapse = "+")
  
  # Cox model
  cox_mod <-
    coxph(formula(
      paste0(
        "Surv(age_entry, age_exit, CVD_event) ~ ",
        form_sum,
        "+ strata(sex)+
  ethnicity + smoking + alcohol + fruit_and_veg_cats + oily_fish + red_and_processed_meat_cats + education_cats + TDI_quartiles"
      )
    ), data = pred_data)
  
  cox_mod_weighted <-
    coxph(formula(
      paste0(
        "Surv(age_entry, age_exit, CVD_event) ~ ",
        form_sum,
        "+ strata(sex)+
  ethnicity + smoking + alcohol + fruit_and_veg_cats + oily_fish + red_and_processed_meat_cats + education_cats + TDI_quartiles"
      )
    ), data = pred_data_weighted)
  
  # Assign Cox model, outputs
  coef <- summary(cox_mod)$coefficients[1, 1]
  se <- summary(cox_mod)$coefficients[1, 3]
  coefs[, paste0(var, "_pivot1_unweighted", c("HR", "HR_Lower_CI", "HR_Upper_CI"))] <-
     exp(c(coef, coef - 1.96*se, coef + 1.96*se))
  rm(coef, se)
  
  coef <- summary(cox_mod_weighted)$coefficients[1, 1]
  se <- summary(cox_mod_weighted)$coefficients[1, 3]
  coefs[, paste0(var, "_pivot1_weighted", c("HR", "HR_Lower_CI", "HR_Upper_CI"))] <- exp(c(coef, coef - 1.96*se, coef + 1.96*se))
  rm(coef, se)
  
}
```

Calc HRs:
```{r}
cm <- epicoda::comp_mean(df, rot_list[[1]])

rec_dat <- make_rec_dat_frame(8)
for (i in 1:length(rot_list)) {
  comp_name <- names(rot_list)[i]
  var_name_weighted <- paste0(comp_name, "_pivot1_weighted")
  var_name_unweighted <- paste0(comp_name, "_pivot1_unweighted")

  # set up for looking at transformation
  diff <- get_diff(comp_name)
  ilr_diff <- create_ref_vals(comp_name, cm)
  
  # Calculate HRs associated with difference
  HRs <- as.double(coefs[, paste0(var_name_weighted, c("HR", "HR_Lower_CI", "HR_Upper_CI"))]) ^ ilr_diff
  rec_dat[(i - 1) * 2 + 1,] <- c(comp_name, diff, "weighted", HRs)
  rm(HRs)
  
  
  HRs <- as.double(coefs[, paste0(var_name_unweighted, c("HR", "HR_Lower_CI", "HR_Upper_CI"))]) ^ ilr_diff
  rec_dat[i * 2,] <- c(comp_name, diff, "unweighted", HRs)
  rm(HRs)
}

print(rec_dat)
```


Conclusion: precision weighting the model makes almost no difference, so keep methodology simple and don't bother. 



# BOOTSTRAPPING 

## Bootstrap the whole procedure
Sampling for the two step bootstrap is non-obvious, to ensure correct sample sizes. I have chosen to sample those with repeated measurements and without separately, to ensure the correct sample size in the final sample. 
```{r}
n_bootstrap <-  1000

# Set up data frame to record estimates
ests <- data.frame(matrix(nrow = n_bootstrap, ncol = length(names(rot_list))))
colnames(ests) <- paste0(names(rot_list), "_pivot1")

# Set up sets of ids/data subsets for sampling
ids_rm <- df_rm$eid
df_non_rm <- df[!(df$eid %in% ids_rm), ]
df_limit <- df[df$eid %in% ids_rm, ]
df_left <- df_limit[order(match(df_limit$eid, df_non_rm$eid)), ]
rm(df_limit) # Keep tidy

for (i in 1:n_bootstrap){
  # SAMPLING-------------------------------------------------------------------------------------
  # Sample those in overlap
  df_rm_rownums_loc <- sample(nrow(df_rm), nrow(df_rm), replace = TRUE)
  df_rm_loc <- df_rm[df_rm_rownums_loc, ]
  df_left_loc <- df_left[df_rm_rownums_loc, ] 
  
  # Check this sampling is behaving correctly 
  if (any(df_left_loc$eid != df_rm_loc$eid)){
    stop("Error in subsetting code")
  }
  
  # Sample those not in overlap
  df_non_rm_loc <- df_non_rm[sample(nrow(df_non_rm), nrow(df_non_rm), replace = TRUE), ]
  
  # Check this sampling is working correctly
  if (length(intersect(df_non_rm_loc$eid, df_left_loc$eid)) != 0){
    stop("Error in sampling code - intersect of datasets non null")
  }
  
  # Concatenate datasets
  df_loc <- rbind(df_non_rm_loc, df_left_loc)
  
  if (nrow(df_loc) != nrow(df)){
    stop("Failure to get correct size bootstrap")
  }
  
#  print(head(df_loc$eid))

  # CALCULATE MODELS IN BOOTSTRAP SAMPLE--------------------------------------------------------------
  # Note we are using same bootstrap samples for all rotations. This makes sense as we are essentially looking at the 
  # same model in these cases
  
  for (var in names(rot_list)){
    # Find names of variables
    form_vars <- colnames(df_rm_loc)[grepl(paste0(var, "z"), colnames(df_rm_loc))]
    form_vars <- unique(gsub("_(.*)", "", form_vars))
  
    # Make all predictive models
    models_list <- calc_models_multi(
      var_names = form_vars,
      data = df_rm_loc,
      suffix_baseline = "_s0",
      suffix_rep = c("_s1", "_s2", "_s3", "_s4"),
      exclusion_indic = "excluded",
      covariates = c("age_entry", "sex", "ethnicity", "smoking", "alcohol", "fruit_and_veg_cats", "oily_fish", "red_and_processed_meat_cats", "education_cats", "TDI_quartiles"), 
      precision_weighted = TRUE
    )
  
    # Make predictions
    pred_data_loc <- pred_rep(models_list, newdata = df_loc, suffix_pred = "_pred")
    
    # Variables for new calculation
    form_vars_new <- paste0(form_vars, "_pred")
    form_sum <- paste0(form_vars_new, collapse = "+")
    
    # Cox model
    cox_mod <- coxph(formula(paste0("Surv(age_entry, age_exit, CVD_event) ~ ", form_sum, "+ strata(sex)+ ethnicity + smoking + alcohol + fruit_and_veg_cats + oily_fish + red_and_processed_meat_cats + education_cats + TDI_quartiles")), data = pred_data_loc)
  
  # Store variables
  ests[i, paste0(var, "_pivot1")] <- summary(cox_mod)$coefficients[1, 1]
  
  } # This closes rotation through different variables as first pivot coordinate
  
  # CLEAN --------------------------------------------------------------------------------
  rm(df_rm_rownums_loc, df_rm_loc, df_left_loc, pred_data_loc, df_loc, df_non_rm_loc)
}

# CHECK 
if (!isTRUE(all.equal(colnames(ests), colnames(coefs)))){
  stop("Something went wrong in column names")
}

# Write out bootstrap for reuse
saveRDS(ests, "bootstrap_ests_precision_weighted_for_reuse.RDS")
```


```{r}
# Now reload data for calculations
ests <- readRDS("bootstrap_ests_precision_weighted_for_reuse.RDS")

# CALCULATE BOOTSTRAP (BASIC OR REVERSE PERCENTILE BOOTSTRAP; PERCENTILE BOOTSTRAP)
## http://users.stat.umn.edu/~helwig/notes/npboot-notes.html#bootstrap-confidence-intervals

# For basic/reverse percentile
diffs <- ests-coefs[rep(1, nrow(ests)), colnames(ests)] # Subtract overall estimate from estimate in bootstrap sample 

# Prep data frame with values and fill it out
vals <- data.frame(matrix(nrow = 4, ncol = 11))
colnames(vals) <- c("Variable", "Estimate", "Lower_CI", "Upper_CI", "HR", "HR_Lower_CI", "HR_Upper_CI", "Lower_CI_percentile", "Upper_CI_percentile",  "HR_Lower_CI_percentile", "HR_Upper_CI_percentile")
for (i in 1:length(rot_list)){
  var_name <- colnames(ests)[i]
  
  # basic/empirical/reverse percentile
  lq <- quantile(diffs[, var_name], 0.025)
  uq <- quantile(diffs[, var_name], 0.975)
  c <- coefs[, var_name]
  uci <- c - lq 
  lci <- c - uq
  
  # percentile
  lqp <- quantile(ests[, var_name], 0.025)
  uqp <- quantile(ests[, var_name], 0.975)
  
  # return 
  vals[i, ] <- c(var_name, c, lci, uci, exp(c), exp(lci), exp(uci), lqp, uqp, exp(lqp), exp(uqp))
  
  # hist of diffs
  print(hist(diffs[, var_name])) # Check reasonableness of bootstrap distributions
}
print(vals)
write.csv(vals, "plots/thesis-cox-coefs-precision-weighted-with-meas-err-adjustment.csv")
```
